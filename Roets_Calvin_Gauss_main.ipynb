{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1HQhnNfZ79jT"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import natsort\n",
        "import re \n",
        "import sys\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Eerst delay_dataset uploaden naar google colab en wachten tot upload compleet is\n",
        "standaarddirectory = os.getcwd()                  #standaarddirectory van google colab opslaan zodat we altijd terug kunnen keren naar deze\n",
        "file_name = \"delay_dataset.zip\"                   #de naam van de zipfile met alle data\n",
        "if not os.path.exists(\"stud_train\"):              #Als de data nog niet uitgepakt is en deze folder dus nog niet bestaat, gaan we dit doen\n",
        "  try:\n",
        "    with ZipFile(file_name,'r') as zipper:\n",
        "      zipper.extractall()\n",
        "      print(\"extractie data klaar\")\n",
        "  except:\n",
        "    sys.exit(\"Fout bij extractie data, zeker dat deze goed is geupload?\")\n",
        "\n",
        "if not os.path.exists(\"stud_train_combined_ASDR\"):    #Een folder waarin we de gecombineerde ASDR train signalen van 1024 samples zullen opslaan\n",
        "  os.makedirs(\"stud_train_combined_ASDR\")\n",
        "if not os.path.exists(\"stud_train_combined_GAUSS\"):   #Een folder waarin we de gecombineerde GAUSS train signalen van 1024 samples zullen opslaan\n",
        "  os.makedirs(\"stud_train_combined_GAUSS\")\n",
        "if not os.path.exists(\"stud_train_combined_SBOX\"):    #Een folder waarin we de gecombineerde SBOX train signalen van 1024 samples zullen opslaan\n",
        "  os.makedirs(\"stud_train_combined_SBOX\")\n",
        "\n",
        "if not os.path.exists(\"stud_test_combined_ASDR\"):    #Een folder waarin we de gecombineerde ASDR test signalen van 1024 samples zullen opslaan\n",
        "  os.makedirs(\"stud_test_combined_ASDR\")\n",
        "if not os.path.exists(\"stud_test_combined_GAUSS\"):   #Een folder waarin we de gecombineerde GAUSS test signalen van 1024 samples zullen opslaan\n",
        "  os.makedirs(\"stud_test_combined_GAUSS\")\n",
        "if not os.path.exists(\"stud_test_combined_SBOX\"):    #Een folder waarin we de gecombineerde SBOX test signalen van 1024 samples zullen opslaan\n",
        "  os.makedirs(\"stud_test_combined_SBOX\")"
      ],
      "metadata": {
        "id": "mgGGxSjv8Icw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# variable declaration\n",
        "train_set = 'stud_train'  #een string voor de folder met de trainsamples\n",
        "test_set = 'stud_test'    #een string voor de folder met de testsamples\n",
        "delaypiekASDR = []    #arrays met werkelijke delays tussen de pieken (cijfers voor training en validatie)\n",
        "delaypiekGAUSS = []\n",
        "delaypiekSBOX = []\n",
        "delaypiekASDRtest = []    #arrays met werkelijke delays tussen de pieken (cijfers voor testing)\n",
        "delaypiekGAUSStest = []\n",
        "delaypiekSBOXtest = []\n",
        "grafieknummer = 0 #variabele voor grafieknummering"
      ],
      "metadata": {
        "id": "sokPDAPy8KV4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Geeft een array met strings weer waarin de namen van de files in die map staan\n",
        "def laadarraymetfilenamenuitmap(map):\n",
        "    filenames = os.listdir(map)  # array met alle filenames van in folder\n",
        "    filenames.sort()\n",
        "    return filenames"
      ],
      "metadata": {
        "id": "TgGQgK3V8M1u"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot het signaal van een numpy array aan de hand van een megegeven signaalbestandsnaam\n",
        "#Functie werd enkel gebruikt in het begin voor de twee verschillende signalen van 512 samples te visualiseren op 1 grafiek, niet meer nodig en niet meer gebruikt verder\n",
        "def plotsignaal(signaal, evencheck, nummer, x = np.arange(0,512)): #signaal is naam bestand tussen aanhalingstekens\n",
        "    if evencheck % 2 == 0:                                        #evencheck wordt gebruikt om elke keer twee signalen samen op 1 grafiek te zetten met elk een verschillend kleur\n",
        "        kleur = \"red\"         #paar van signalen respectievelijk rood en blauw weergeven zodat het verschil duidelijk is\n",
        "    else:\n",
        "        kleur = \"blue\"\n",
        "    plot = plt.figure(nummer)\n",
        "    plt.xlabel(\"samples\")\n",
        "    plt.ylabel(\"amplitude\")\n",
        "    plt.plot(x,np.load(signaal), color=kleur)"
      ],
      "metadata": {
        "id": "ddKNHGvW8Ok1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Geeft de waarde van de positie van die piek terug aan de hand van de bestandsnaam\n",
        "def geefpositiepiek(signaal):\n",
        "  truncatedsignaal = (signaal.split(\"P_\",1)[1]) #alles voor de xxx wegdoen dus BV ASDR0_P_ wegdoen\n",
        "  piek = ''.join(x for x in truncatedsignaal[0:3] if x.isdigit()) #drie eerstvolgende karakters overlopen en als deze een cijfer is, maakt deze deel uit van de piek bv: 211_SNR20 wordt 211, 8_SNR26 wordt 8\n",
        "  return piek"
      ],
      "metadata": {
        "id": "W3pSnBvJ8QUP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#voegt de array van twee signalen samen om 1 vector van 1024 samples te bekomen\n",
        "def voegsamen(signaal1, signaal2):\n",
        "  return np.concatenate([np.load(signaal1), np.load(signaal2)])"
      ],
      "metadata": {
        "id": "xzRdHkg08R93"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wordt gebruikt om de lijst met de files te sorten op numerische orde ipv alfabetische orde om sortering van 0 1 10 11 ... 19 2 20 21 ... 29 3 30 31 etc te voorkomen maar 0 1 2 3 4 ... 99\n",
        "#outsourced functies\n",
        "def atoi(text):\n",
        "    return int(text) if text.isdigit() else text\n",
        "\n",
        "def natural_keys(text):\n",
        "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
      ],
      "metadata": {
        "id": "RIRBSs8k8TcZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wordt gebruikt om de 200 signalen van 512 te combineren naar 100 van 1024\n",
        "def combinedata(folder, dir, delayarray, typesignaal = \"\", testoftrain = \"\", aantalgrafiekenplotten = 0):\n",
        "  nummer, evencheck = 1, 0\n",
        "  for data in folder:\n",
        "    evencheck += 1\n",
        "    if evencheck % 2 == 0:     #controleert als we aan een even file zitten, zodat we deze kunnen samenvoegen met de oneven file die ervoor kwam\n",
        "      os.chdir(f\"stud_{testoftrain}\")         #folder binnengaan waar we willen samenvoegen\n",
        "      masterfile = voegsamen(previous, data) #masterfile is een array van 1024 nu\n",
        "      os.chdir(standaarddirectory)\n",
        "      os.chdir(dir)                         #folder binnengaan waar we willen saven\n",
        "      savename = f\"{nummer}{typesignaal}.npy\"\n",
        "      np.save(savename,masterfile)\n",
        "      os.chdir(standaarddirectory)\n",
        "      nummer += 1\n",
        "      delayarray.append(512-int(geefpositiepiek(previous))+int(geefpositiepiek(data)))    #512-piek1+piek2 is waarde van delay\n",
        "\n",
        "      #plotten voor eerste paar grafieken, mooie visualisatie als controle, wordt als default niet gedaan want variabele aantalgrafiekenplotten is 0\n",
        "      if nummer <= aantalgrafiekenplotten:  #max 20 grafieken door memory limiet, dus aantalgrafiekenplotten niet groter dan 20 maken\n",
        "        plot= plt.figure(nummer)\n",
        "        plt.plot(np.arange(0, 1024),masterfile, color=\"red\")\n",
        "\n",
        "    previous = data"
      ],
      "metadata": {
        "id": "COoxeWEx8VB9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotpredictieerrors(predictionslist, delaypiek, titel = '', typesign = 'test'):\n",
        "  global grafieknummer\n",
        "\n",
        "  #x zorgt voor een juiste dimensionering van de x as in de grafiek\n",
        "  if typesign == 'test':\n",
        "    x = 100+1\n",
        "  elif typesign == 'train':\n",
        "    x = 90+1\n",
        "  elif typesign == 'validation':\n",
        "    x = 10+1\n",
        "  elif typesign == 'totaltest':\n",
        "    x = 3*100+1\n",
        "  elif typesign == 'totaltrain':\n",
        "    x = 3*90+1\n",
        "  elif typesign == 'totalvalidation':\n",
        "    x = 3*10+1\n",
        "\n",
        "  error_list = []   #absolute waarde van de fout van predictie \n",
        "  for error1, error2 in zip(predictionslist, delaypiek):\n",
        "    error_list.append(round(abs(error1 - error2)))\n",
        "\n",
        "  y = (sum(error_list)/len(error_list)) #y waarde voor schaling y as grafiek\n",
        "  print(\"De errors zijn (afgerond tot gehele waarden):\")\n",
        "  print(error_list)\n",
        "  print(\"De predicties zijn:\")\n",
        "  print(predictionslist)\n",
        "  print(\"De werkelijke waarden zijn:\")\n",
        "  print(delaypiek)\n",
        "\n",
        "  #visualiseren error\n",
        "  bar = plt.figure(grafieknummer)\n",
        "  grafieknummer += 1\n",
        "  plt.bar(np.arange(1, x), error_list)\n",
        "  plt.ylim(0, y+25)\n",
        "  plt.title(titel)\n",
        "  plt.show()\n",
        "  print() "
      ],
      "metadata": {
        "id": "fTOu4cxI8W0p"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main\n",
        "#filenames inlezen\n",
        "filenames = laadarraymetfilenamenuitmap(train_set)\n",
        "filenamesASDR = filenames[0:200]\n",
        "filenamesGAUSS = filenames[200:400]\n",
        "filenamesSBOX = filenames[400:600]\n",
        "\n",
        "filenamestest = laadarraymetfilenamenuitmap(test_set)\n",
        "filenamesASDRtest = filenamestest[0:200]\n",
        "filenamesGAUSStest = filenamestest[200:400]\n",
        "filenamesSBOXtest = filenamestest[400:600]\n",
        "\n",
        "#sorteren op numerische wijze ipv alfabetische wijze\n",
        "filenamesASDR.sort(key=natural_keys)\n",
        "filenamesGAUSS.sort(key=natural_keys)\n",
        "filenamesSBOX.sort(key=natural_keys)\n",
        "filenamesASDRtest.sort(key=natural_keys)\n",
        "filenamesGAUSStest.sort(key=natural_keys)\n",
        "filenamesSBOXtest.sort(key=natural_keys)"
      ],
      "metadata": {
        "id": "UDMNtMCl8ZeF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(standaarddirectory)\n",
        "#Nu gaan we de 6 folders opvullen waarin de files gecombineerd worden tot 100 signalen van 1024 samples\n",
        "combinedata(filenamesASDR, \"stud_train_combined_ASDR\", delaypiekASDR, \"ASDR\", \"train\")\n",
        "combinedata(filenamesGAUSS, \"stud_train_combined_GAUSS\", delaypiekGAUSS, \"GAUSS\", \"train\")\n",
        "combinedata(filenamesSBOX, \"stud_train_combined_SBOX\", delaypiekSBOX, \"SBOX\", \"train\")\n",
        "\n",
        "combinedata(filenamesASDRtest, \"stud_test_combined_ASDR\", delaypiekASDRtest, \"ASDR\", \"test\")\n",
        "combinedata(filenamesGAUSStest, \"stud_test_combined_GAUSS\", delaypiekGAUSStest, \"GAUSS\", \"test\")\n",
        "combinedata(filenamesSBOXtest, \"stud_test_combined_SBOX\", delaypiekSBOXtest, \"SBOX\", \"test\")"
      ],
      "metadata": {
        "id": "T7z9o7Qt8j2r"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEURAL NETWERK MODEL"
      ],
      "metadata": {
        "id": "xSd4YnRa8nTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TENSOR Object maken voor x waarden NN training\n",
        "os.chdir(standaarddirectory)\n",
        "os.chdir(\"stud_train_combined_GAUSS\")\n",
        "\n",
        "#Traindata\n",
        "#We gebruiken deze traindata om het NN te trainen\n",
        "samplesGAUSS = [np.load(f\"{x}GAUSS.npy\") for x in range(1, 91)]\n",
        "samplesGAUSS = tf.convert_to_tensor(samplesGAUSS)\n",
        "\n",
        "#Validatiedata\n",
        "#We gebruiken de laatste 10% als validatiedata, deze data gebruiken we om de performantie van het NN te evalueren TIJDENS het trainen en zo de hyperparameters aan te passen. Het nn ziet validatiedata NIET op voorhand, in tegenstelling tot trainingsdata\n",
        "samplesGAUSSvalidation = [np.load(f\"{x}GAUSS.npy\") for x in range(91, 101)]\n",
        "samplesGAUSSvalidation = tf.convert_to_tensor(samplesGAUSSvalidation)\n",
        "\n",
        "os.chdir(standaarddirectory)"
      ],
      "metadata": {
        "id": "tWaRs95a8lPl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TENSOR Object maken voor x waarden NN testing\n",
        "os.chdir(standaarddirectory)\n",
        "os.chdir(\"stud_test_combined_GAUSS\")\n",
        "\n",
        "samplesGAUSStest = [np.load(f\"{x}GAUSS.npy\") for x in range(1, 101)]\n",
        "samplesGAUSStest = tf.convert_to_tensor(samplesGAUSStest)\n",
        "\n",
        "os.chdir(standaarddirectory)"
      ],
      "metadata": {
        "id": "pY2AgZj59S6E"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TENSOR object maken voor y waarden NN training (de delaywaarden tussen de pieken)\n",
        "\n",
        "#Traindata\n",
        "delayGAUSS = pd.DataFrame(data = delaypiekGAUSS[0:90])\n",
        "delayGAUSS = tf.convert_to_tensor(delayGAUSS)\n",
        "\n",
        "#Validatiedata\n",
        "delayGAUSSvalidation = pd.DataFrame(data = delaypiekGAUSS[90:])\n",
        "delayGAUSSvalidation = tf.convert_to_tensor(delayGAUSSvalidation)"
      ],
      "metadata": {
        "id": "H6kvZ94P9UXm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model aanmaken\n",
        "modelGAUSS = tf.keras.Sequential()\n",
        "modelGAUSS.add(layers.Dense(512, activation='relu', input_shape=(1024,)))\n",
        "modelGAUSS.add(layers.Dense(256, activation='relu'))\n",
        "modelGAUSS.add(layers.Dense(64, activation='relu'))\n",
        "modelGAUSS.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "jRNaktED9VyH"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelGAUSS.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkC6QdzI9XCh",
        "outputId": "31968709-61ce-44d7-d249-b173ad046192"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 672,641\n",
            "Trainable params: 672,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimizer, loss function en metrics toevoegen aan model en compileren\n",
        "modelGAUSS.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "K.set_value(modelGAUSS.optimizer.learning_rate, 0.0001)"
      ],
      "metadata": {
        "id": "zd3mwu-F9YUi"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Trainen\n",
        "history2 = modelGAUSS.fit(samplesGAUSS,\n",
        "                        delayGAUSS,\n",
        "                        epochs=200,\n",
        "                        validation_data=(samplesGAUSSvalidation,delayGAUSSvalidation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFcH8a1W9ZwP",
        "outputId": "6e1b57d4-8ad9-4556-b434-fc8bdd48d133"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3/3 [==============================] - 1s 83ms/step - loss: 335116.1875 - mse: 335116.1875 - val_loss: 333707.5625 - val_mse: 333707.5625\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 331355.0000 - mse: 331355.0000 - val_loss: 330134.4375 - val_mse: 330134.4375\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 328032.8125 - mse: 328032.8125 - val_loss: 326631.3125 - val_mse: 326631.3125\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 324589.1875 - mse: 324589.1875 - val_loss: 322775.3125 - val_mse: 322775.3125\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 320828.8125 - mse: 320828.8125 - val_loss: 318588.0625 - val_mse: 318588.0625\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 316520.5312 - mse: 316520.5312 - val_loss: 313905.6562 - val_mse: 313905.6562\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 311705.9688 - mse: 311705.9688 - val_loss: 308589.1875 - val_mse: 308589.1875\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 306302.2188 - mse: 306302.2188 - val_loss: 302435.8125 - val_mse: 302435.8125\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 300043.3438 - mse: 300043.3438 - val_loss: 295371.0625 - val_mse: 295371.0625\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 292974.3750 - mse: 292974.3750 - val_loss: 287264.9062 - val_mse: 287264.9062\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 284865.0938 - mse: 284865.0938 - val_loss: 277987.6562 - val_mse: 277987.6562\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 275690.1250 - mse: 275690.1250 - val_loss: 267511.5625 - val_mse: 267511.5625\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 265255.4688 - mse: 265255.4688 - val_loss: 255650.4688 - val_mse: 255650.4688\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 253469.2500 - mse: 253469.2500 - val_loss: 242421.9062 - val_mse: 242421.9062\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 240286.0000 - mse: 240286.0000 - val_loss: 227777.2969 - val_mse: 227777.2969\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 225530.5625 - mse: 225530.5625 - val_loss: 211742.4062 - val_mse: 211742.4062\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 209406.0625 - mse: 209406.0625 - val_loss: 194348.1562 - val_mse: 194348.1562\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 191830.4375 - mse: 191830.4375 - val_loss: 175730.4688 - val_mse: 175730.4688\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 172962.6875 - mse: 172962.6875 - val_loss: 155911.5781 - val_mse: 155911.5781\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 152960.3281 - mse: 152960.3281 - val_loss: 135260.4688 - val_mse: 135260.4688\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 132064.4062 - mse: 132064.4062 - val_loss: 114226.4219 - val_mse: 114226.4219\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 110966.0000 - mse: 110966.0000 - val_loss: 93106.4219 - val_mse: 93106.4219\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 89733.2031 - mse: 89733.2031 - val_loss: 72689.2109 - val_mse: 72689.2109\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 69366.2891 - mse: 69366.2891 - val_loss: 53608.1562 - val_mse: 53608.1562\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 50614.3320 - mse: 50614.3320 - val_loss: 36676.2773 - val_mse: 36676.2773\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 33992.4414 - mse: 33992.4414 - val_loss: 22627.8652 - val_mse: 22627.8652\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 20673.8105 - mse: 20673.8105 - val_loss: 12044.7900 - val_mse: 12044.7900\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 10733.0068 - mse: 10733.0068 - val_loss: 5256.9678 - val_mse: 5256.9678\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4492.6680 - mse: 4492.6680 - val_loss: 1980.7083 - val_mse: 1980.7083\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1683.9526 - mse: 1683.9526 - val_loss: 1462.7095 - val_mse: 1462.7095\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1078.8385 - mse: 1078.8385 - val_loss: 2486.0430 - val_mse: 2486.0430\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1920.7915 - mse: 1920.7915 - val_loss: 3801.2148 - val_mse: 3801.2148\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2797.6045 - mse: 2797.6045 - val_loss: 4530.1074 - val_mse: 4530.1074\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3088.6421 - mse: 3088.6421 - val_loss: 4411.4111 - val_mse: 4411.4111\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2747.9680 - mse: 2747.9680 - val_loss: 3712.9421 - val_mse: 3712.9421\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2090.3652 - mse: 2090.3652 - val_loss: 2784.6450 - val_mse: 2784.6450\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1320.3679 - mse: 1320.3679 - val_loss: 1968.3549 - val_mse: 1968.3549\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 841.1868 - mse: 841.1868 - val_loss: 1392.9008 - val_mse: 1392.9008\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 564.7125 - mse: 564.7125 - val_loss: 1063.3945 - val_mse: 1063.3945\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 498.1786 - mse: 498.1786 - val_loss: 897.7437 - val_mse: 897.7437\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 525.2101 - mse: 525.2101 - val_loss: 822.4466 - val_mse: 822.4466\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 550.5830 - mse: 550.5830 - val_loss: 789.8141 - val_mse: 789.8141\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 553.0333 - mse: 553.0333 - val_loss: 776.0646 - val_mse: 776.0646\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 520.3594 - mse: 520.3594 - val_loss: 779.2049 - val_mse: 779.2049\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 473.6911 - mse: 473.6911 - val_loss: 806.8073 - val_mse: 806.8073\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 423.7177 - mse: 423.7177 - val_loss: 859.0311 - val_mse: 859.0311\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 380.6486 - mse: 380.6486 - val_loss: 923.2103 - val_mse: 923.2103\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 353.9640 - mse: 353.9640 - val_loss: 988.2547 - val_mse: 988.2547\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 341.9677 - mse: 341.9677 - val_loss: 1044.5754 - val_mse: 1044.5754\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 336.3617 - mse: 336.3617 - val_loss: 1083.5005 - val_mse: 1083.5005\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 330.7325 - mse: 330.7325 - val_loss: 1097.4886 - val_mse: 1097.4886\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 324.7363 - mse: 324.7363 - val_loss: 1090.9714 - val_mse: 1090.9714\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 316.0519 - mse: 316.0519 - val_loss: 1075.6218 - val_mse: 1075.6218\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 306.8358 - mse: 306.8358 - val_loss: 1053.8040 - val_mse: 1053.8040\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 298.4763 - mse: 298.4763 - val_loss: 1026.8855 - val_mse: 1026.8855\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 293.2923 - mse: 293.2923 - val_loss: 998.3607 - val_mse: 998.3607\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 285.0675 - mse: 285.0675 - val_loss: 984.9432 - val_mse: 984.9432\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 280.0298 - mse: 280.0298 - val_loss: 977.0703 - val_mse: 977.0703\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 275.1095 - mse: 275.1095 - val_loss: 979.6097 - val_mse: 979.6097\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 270.2386 - mse: 270.2386 - val_loss: 978.9370 - val_mse: 978.9370\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 265.4270 - mse: 265.4270 - val_loss: 983.9323 - val_mse: 983.9323\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 260.3301 - mse: 260.3301 - val_loss: 992.7020 - val_mse: 992.7020\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 255.8654 - mse: 255.8654 - val_loss: 1005.4497 - val_mse: 1005.4497\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 251.2151 - mse: 251.2151 - val_loss: 1016.4899 - val_mse: 1016.4899\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 247.4717 - mse: 247.4717 - val_loss: 1027.6309 - val_mse: 1027.6309\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 243.4610 - mse: 243.4610 - val_loss: 1032.7561 - val_mse: 1032.7561\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 239.3062 - mse: 239.3062 - val_loss: 1035.1400 - val_mse: 1035.1400\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 235.5552 - mse: 235.5552 - val_loss: 1036.6515 - val_mse: 1036.6515\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 231.8934 - mse: 231.8934 - val_loss: 1038.1155 - val_mse: 1038.1155\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 228.2139 - mse: 228.2139 - val_loss: 1039.3807 - val_mse: 1039.3807\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 224.5263 - mse: 224.5263 - val_loss: 1040.5800 - val_mse: 1040.5800\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 221.1361 - mse: 221.1361 - val_loss: 1045.4749 - val_mse: 1045.4749\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 217.5393 - mse: 217.5393 - val_loss: 1045.9034 - val_mse: 1045.9034\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 214.2244 - mse: 214.2244 - val_loss: 1050.0341 - val_mse: 1050.0341\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 210.8360 - mse: 210.8360 - val_loss: 1047.2396 - val_mse: 1047.2396\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 207.7095 - mse: 207.7095 - val_loss: 1048.9645 - val_mse: 1048.9645\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 204.4502 - mse: 204.4502 - val_loss: 1047.8931 - val_mse: 1047.8931\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 201.0869 - mse: 201.0869 - val_loss: 1052.7944 - val_mse: 1052.7944\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 198.1343 - mse: 198.1343 - val_loss: 1057.7081 - val_mse: 1057.7081\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 194.9689 - mse: 194.9689 - val_loss: 1060.5603 - val_mse: 1060.5603\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 191.9402 - mse: 191.9402 - val_loss: 1062.9607 - val_mse: 1062.9607\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 189.0867 - mse: 189.0867 - val_loss: 1068.6387 - val_mse: 1068.6387\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 185.9177 - mse: 185.9177 - val_loss: 1072.4235 - val_mse: 1072.4235\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 183.2157 - mse: 183.2157 - val_loss: 1071.0549 - val_mse: 1071.0549\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 180.3145 - mse: 180.3145 - val_loss: 1071.9338 - val_mse: 1071.9338\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 177.4152 - mse: 177.4152 - val_loss: 1073.5421 - val_mse: 1073.5421\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 174.4680 - mse: 174.4680 - val_loss: 1076.1116 - val_mse: 1076.1116\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 171.9561 - mse: 171.9561 - val_loss: 1075.6254 - val_mse: 1075.6254\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 168.8766 - mse: 168.8766 - val_loss: 1081.8785 - val_mse: 1081.8785\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 166.3667 - mse: 166.3667 - val_loss: 1087.3918 - val_mse: 1087.3918\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 163.5889 - mse: 163.5889 - val_loss: 1090.8057 - val_mse: 1090.8057\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 161.4341 - mse: 161.4341 - val_loss: 1092.8314 - val_mse: 1092.8314\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 158.3966 - mse: 158.3966 - val_loss: 1089.7046 - val_mse: 1089.7046\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 156.0786 - mse: 156.0786 - val_loss: 1085.0029 - val_mse: 1085.0029\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 153.4922 - mse: 153.4922 - val_loss: 1081.6046 - val_mse: 1081.6046\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 150.8244 - mse: 150.8244 - val_loss: 1084.8575 - val_mse: 1084.8575\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 148.5710 - mse: 148.5710 - val_loss: 1087.9921 - val_mse: 1087.9921\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 146.0253 - mse: 146.0253 - val_loss: 1093.3876 - val_mse: 1093.3876\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 143.8059 - mse: 143.8059 - val_loss: 1094.3269 - val_mse: 1094.3269\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 142.1343 - mse: 142.1343 - val_loss: 1102.9763 - val_mse: 1102.9763\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 138.9462 - mse: 138.9462 - val_loss: 1107.7758 - val_mse: 1107.7758\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 137.0323 - mse: 137.0323 - val_loss: 1113.5214 - val_mse: 1113.5214\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 134.5931 - mse: 134.5931 - val_loss: 1113.0885 - val_mse: 1113.0885\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 132.3097 - mse: 132.3097 - val_loss: 1109.0530 - val_mse: 1109.0530\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 130.2566 - mse: 130.2566 - val_loss: 1111.6929 - val_mse: 1111.6929\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 128.0945 - mse: 128.0945 - val_loss: 1111.4784 - val_mse: 1111.4784\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 125.8142 - mse: 125.8142 - val_loss: 1109.7012 - val_mse: 1109.7012\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 124.1240 - mse: 124.1240 - val_loss: 1115.1604 - val_mse: 1115.1604\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 121.9735 - mse: 121.9735 - val_loss: 1111.4440 - val_mse: 1111.4440\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 119.8272 - mse: 119.8272 - val_loss: 1113.7391 - val_mse: 1113.7391\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 117.9047 - mse: 117.9047 - val_loss: 1114.7236 - val_mse: 1114.7236\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 115.9293 - mse: 115.9293 - val_loss: 1117.0981 - val_mse: 1117.0981\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 113.8941 - mse: 113.8941 - val_loss: 1121.6215 - val_mse: 1121.6215\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 111.9475 - mse: 111.9475 - val_loss: 1125.4867 - val_mse: 1125.4867\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 110.1567 - mse: 110.1567 - val_loss: 1133.1941 - val_mse: 1133.1941\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 108.2622 - mse: 108.2622 - val_loss: 1136.4818 - val_mse: 1136.4818\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 106.5226 - mse: 106.5226 - val_loss: 1139.2664 - val_mse: 1139.2664\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 104.7690 - mse: 104.7690 - val_loss: 1139.2523 - val_mse: 1139.2523\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 102.9344 - mse: 102.9344 - val_loss: 1135.4128 - val_mse: 1135.4128\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 101.0855 - mse: 101.0855 - val_loss: 1135.3411 - val_mse: 1135.3411\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 99.3819 - mse: 99.3819 - val_loss: 1133.6333 - val_mse: 1133.6333\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 97.9886 - mse: 97.9886 - val_loss: 1137.8375 - val_mse: 1137.8375\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 96.0462 - mse: 96.0462 - val_loss: 1135.1492 - val_mse: 1135.1492\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 94.3622 - mse: 94.3622 - val_loss: 1135.8992 - val_mse: 1135.8992\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 93.2351 - mse: 93.2351 - val_loss: 1146.6125 - val_mse: 1146.6125\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 90.9778 - mse: 90.9778 - val_loss: 1146.3208 - val_mse: 1146.3208\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 89.5964 - mse: 89.5964 - val_loss: 1146.6525 - val_mse: 1146.6525\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 88.0398 - mse: 88.0398 - val_loss: 1151.7345 - val_mse: 1151.7345\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 86.4978 - mse: 86.4978 - val_loss: 1150.1840 - val_mse: 1150.1840\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 84.8712 - mse: 84.8712 - val_loss: 1153.1959 - val_mse: 1153.1959\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 83.7157 - mse: 83.7157 - val_loss: 1151.6333 - val_mse: 1151.6333\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 82.0485 - mse: 82.0485 - val_loss: 1157.0405 - val_mse: 1157.0405\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 80.5910 - mse: 80.5910 - val_loss: 1161.0284 - val_mse: 1161.0284\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 79.1925 - mse: 79.1925 - val_loss: 1160.3450 - val_mse: 1160.3450\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 77.7705 - mse: 77.7705 - val_loss: 1162.3687 - val_mse: 1162.3687\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 76.4308 - mse: 76.4308 - val_loss: 1166.1482 - val_mse: 1166.1482\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 74.9949 - mse: 74.9949 - val_loss: 1166.0535 - val_mse: 1166.0535\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 73.7720 - mse: 73.7720 - val_loss: 1165.5914 - val_mse: 1165.5914\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 72.4323 - mse: 72.4323 - val_loss: 1171.4913 - val_mse: 1171.4913\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 71.1015 - mse: 71.1015 - val_loss: 1173.4988 - val_mse: 1173.4988\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 69.9456 - mse: 69.9456 - val_loss: 1177.9440 - val_mse: 1177.9440\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 68.7320 - mse: 68.7320 - val_loss: 1174.5371 - val_mse: 1174.5371\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 67.5708 - mse: 67.5708 - val_loss: 1176.4303 - val_mse: 1176.4303\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 66.1242 - mse: 66.1242 - val_loss: 1176.4149 - val_mse: 1176.4149\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 65.1309 - mse: 65.1309 - val_loss: 1174.9718 - val_mse: 1174.9718\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 63.7801 - mse: 63.7801 - val_loss: 1180.8137 - val_mse: 1180.8137\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 62.7539 - mse: 62.7539 - val_loss: 1183.3336 - val_mse: 1183.3336\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 61.5489 - mse: 61.5489 - val_loss: 1188.2150 - val_mse: 1188.2150\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 60.5124 - mse: 60.5124 - val_loss: 1192.3317 - val_mse: 1192.3317\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 59.3732 - mse: 59.3732 - val_loss: 1197.5974 - val_mse: 1197.5974\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 58.3266 - mse: 58.3266 - val_loss: 1204.0011 - val_mse: 1204.0011\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 57.3605 - mse: 57.3605 - val_loss: 1207.2870 - val_mse: 1207.2870\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 56.3800 - mse: 56.3800 - val_loss: 1200.9081 - val_mse: 1200.9081\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 55.2920 - mse: 55.2920 - val_loss: 1198.7457 - val_mse: 1198.7457\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 54.4081 - mse: 54.4081 - val_loss: 1194.4375 - val_mse: 1194.4375\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 53.4198 - mse: 53.4198 - val_loss: 1193.0602 - val_mse: 1193.0602\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 52.2276 - mse: 52.2276 - val_loss: 1200.5032 - val_mse: 1200.5032\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 51.3358 - mse: 51.3358 - val_loss: 1207.0608 - val_mse: 1207.0608\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 50.3945 - mse: 50.3945 - val_loss: 1207.6642 - val_mse: 1207.6642\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 49.5319 - mse: 49.5319 - val_loss: 1213.0382 - val_mse: 1213.0382\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 48.6974 - mse: 48.6974 - val_loss: 1210.7659 - val_mse: 1210.7659\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 48.0126 - mse: 48.0126 - val_loss: 1218.6400 - val_mse: 1218.6400\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 46.9551 - mse: 46.9551 - val_loss: 1214.5200 - val_mse: 1214.5200\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 45.9862 - mse: 45.9862 - val_loss: 1211.8186 - val_mse: 1211.8186\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 45.1479 - mse: 45.1479 - val_loss: 1208.9795 - val_mse: 1208.9795\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 44.7361 - mse: 44.7361 - val_loss: 1205.5309 - val_mse: 1205.5309\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 43.6919 - mse: 43.6919 - val_loss: 1216.5951 - val_mse: 1216.5951\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 42.7490 - mse: 42.7490 - val_loss: 1222.6632 - val_mse: 1222.6632\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 41.9365 - mse: 41.9365 - val_loss: 1226.9248 - val_mse: 1226.9248\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 41.2329 - mse: 41.2329 - val_loss: 1229.7622 - val_mse: 1229.7622\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 40.4517 - mse: 40.4517 - val_loss: 1231.1969 - val_mse: 1231.1969\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 39.7573 - mse: 39.7573 - val_loss: 1226.3158 - val_mse: 1226.3158\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 38.9768 - mse: 38.9768 - val_loss: 1225.9093 - val_mse: 1225.9093\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 38.3583 - mse: 38.3583 - val_loss: 1227.9595 - val_mse: 1227.9595\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 37.5368 - mse: 37.5368 - val_loss: 1229.4338 - val_mse: 1229.4338\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 36.9671 - mse: 36.9671 - val_loss: 1225.9907 - val_mse: 1225.9907\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 36.2475 - mse: 36.2475 - val_loss: 1232.6083 - val_mse: 1232.6083\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 35.5439 - mse: 35.5439 - val_loss: 1236.0649 - val_mse: 1236.0649\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 34.8565 - mse: 34.8565 - val_loss: 1236.9631 - val_mse: 1236.9631\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 34.2261 - mse: 34.2261 - val_loss: 1235.6672 - val_mse: 1235.6672\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 33.6134 - mse: 33.6134 - val_loss: 1236.5601 - val_mse: 1236.5601\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 33.2479 - mse: 33.2479 - val_loss: 1244.7594 - val_mse: 1244.7594\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 32.3613 - mse: 32.3613 - val_loss: 1242.4933 - val_mse: 1242.4933\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 31.7621 - mse: 31.7621 - val_loss: 1241.4432 - val_mse: 1241.4432\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 31.2261 - mse: 31.2261 - val_loss: 1243.7262 - val_mse: 1243.7262\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 30.5781 - mse: 30.5781 - val_loss: 1242.8420 - val_mse: 1242.8420\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 30.0727 - mse: 30.0727 - val_loss: 1243.7942 - val_mse: 1243.7942\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 29.5383 - mse: 29.5383 - val_loss: 1246.5647 - val_mse: 1246.5647\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 28.9781 - mse: 28.9781 - val_loss: 1243.8745 - val_mse: 1243.8745\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 28.4201 - mse: 28.4201 - val_loss: 1243.7430 - val_mse: 1243.7430\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 28.0115 - mse: 28.0115 - val_loss: 1249.3134 - val_mse: 1249.3134\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 27.5630 - mse: 27.5630 - val_loss: 1244.6755 - val_mse: 1244.6755\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 26.8630 - mse: 26.8630 - val_loss: 1249.4895 - val_mse: 1249.4895\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 26.3667 - mse: 26.3667 - val_loss: 1253.1562 - val_mse: 1253.1562\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 25.8577 - mse: 25.8577 - val_loss: 1259.2469 - val_mse: 1259.2469\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 25.3835 - mse: 25.3835 - val_loss: 1260.6517 - val_mse: 1260.6517\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 24.9391 - mse: 24.9391 - val_loss: 1265.3492 - val_mse: 1265.3492\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 24.4724 - mse: 24.4724 - val_loss: 1267.1267 - val_mse: 1267.1267\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 24.0258 - mse: 24.0258 - val_loss: 1267.0457 - val_mse: 1267.0457\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 23.5792 - mse: 23.5792 - val_loss: 1266.3522 - val_mse: 1266.3522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictionsGAUSS = modelGAUSS.predict(samplesGAUSStest)\n",
        "predictionsGAUSStrain = modelGAUSS.predict(samplesGAUSS) #Ook eens testen op traindata voor controle\n",
        "predictionsGAUSSval = modelGAUSS.predict(samplesGAUSSvalidation) #Ook eens testen op validatiedata voor controle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEOVnT6w9brh",
        "outputId": "f2f83630-5e14-49d1-83ce-f655cf149d3f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 5ms/step\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotten van de errors op testdata\n",
        "predictionslistGAUSS = predictionsGAUSS.tolist()  #converteren naar lijst\n",
        "predictionslistGAUSSflat = [item for sublist in predictionslistGAUSS for item in sublist] #lijst plat maken\n",
        "plotpredictieerrors(predictionslistGAUSSflat, delaypiekGAUSStest, \"GAUSStestset\")\n",
        "\n",
        "#plotten van de errors op traindata\n",
        "predictionslistGAUSStrain = predictionsGAUSStrain.tolist()\n",
        "predictionslistGAUSStrainflat = [item for sublist in predictionslistGAUSStrain for item in sublist] #lijst plat maken\n",
        "plotpredictieerrors(predictionslistGAUSStrainflat, delaypiekGAUSS[0:90], \"GAUSStrainset\", 'train')\n",
        "\n",
        "#plotten van de errors op validatiedata\n",
        "predictionslistGAUSSval = predictionsGAUSSval.tolist()\n",
        "predictionslistGAUSSvalflat = [item for sublist in predictionslistGAUSSval for item in sublist] #lijst plat maken\n",
        "\n",
        "plotpredictieerrors(predictionslistGAUSSvalflat, delaypiekGAUSS[90:], \"GAUSSvalidatieset\", 'validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RYCXN4rs9dV8",
        "outputId": "9429262c-2932-4888-8472-383543fd9ea2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "De errors zijn (afgerond tot gehele waarden):\n",
            "[35, 3, 7, 11, 2, 8, 4, 11, 20, 5, 3, 4, 2, 5, 13, 24, 3, 10, 3, 7, 5, 5, 1, 29, 2, 15, 10, 1, 4, 4, 15, 26, 5, 27, 2, 7, 3, 12, 6, 16, 5, 13, 6, 1, 3, 9, 3, 144, 694, 2, 3, 23, 6, 14, 120, 6, 3, 1, 23, 1, 2, 2, 0, 41, 0, 4, 10, 13, 3, 124, 3, 4, 65, 22, 15, 4, 12, 5, 1, 3, 4, 9, 38, 4, 3, 23, 3, 1, 29, 16, 2, 29, 12, 13, 1, 11, 6, 8, 3, 2]\n",
            "De predicties zijn:\n",
            "[586.9605102539062, 586.4437866210938, 559.6734619140625, 593.3735961914062, 555.8364868164062, 564.126953125, 593.1610107421875, 565.209228515625, 590.7212524414062, 591.3403930664062, 581.7783813476562, 570.8683471679688, 587.3255004882812, 600.3840942382812, 592.4774169921875, 612.2390747070312, 583.8209228515625, 558.220458984375, 558.0849609375, 602.3766479492188, 599.0731811523438, 600.3007202148438, 564.2161254882812, 588.077880859375, 560.0957641601562, 562.34716796875, 590.8324584960938, 604.7841186523438, 603.4110717773438, 559.0718383789062, 560.206787109375, 592.123779296875, 598.7940063476562, 586.0160522460938, 584.7329711914062, 602.0043334960938, 594.3771362304688, 598.5060424804688, 602.2938232421875, 592.0667114257812, 595.9755859375, 585.9725952148438, 588.6087036132812, 598.9154052734375, 595.830078125, 595.4937744140625, 559.8787841796875, 705.395263671875, 1255.7781982421875, 601.4619750976562, 547.3958129882812, 583.2637329101562, 598.7576293945312, 588.1591186523438, 731.19384765625, 584.2062377929688, 592.9681396484375, 581.2704467773438, 573.62744140625, 580.2659301757812, 596.9593505859375, 598.4098510742188, 570.1767578125, 612.81787109375, 565.4127197265625, 601.3592529296875, 599.4579467773438, 592.7691650390625, 593.89697265625, 719.8593139648438, 588.7571411132812, 549.8854370117188, 629.8134765625, 578.2344360351562, 595.3341674804688, 553.0983276367188, 576.6087036132812, 600.3715209960938, 597.5783081054688, 601.5397338867188, 602.710693359375, 575.6878051757812, 587.6885375976562, 591.7890625, 587.6723022460938, 582.2398071289062, 606.423583984375, 544.0371704101562, 571.4795532226562, 594.2315673828125, 543.8363647460938, 584.879150390625, 600.1135864257812, 584.1340942382812, 586.7909545898438, 614.5676879882812, 554.2453002929688, 585.7044067382812, 590.9490966796875, 572.6279907226562]\n",
            "De werkelijke waarden zijn:\n",
            "[552, 589, 553, 604, 554, 556, 597, 554, 611, 586, 579, 575, 589, 605, 605, 588, 587, 548, 555, 609, 604, 605, 563, 559, 558, 547, 601, 606, 607, 555, 545, 566, 604, 559, 583, 609, 597, 611, 608, 576, 591, 573, 595, 600, 599, 604, 557, 561, 562, 599, 544, 560, 605, 574, 611, 590, 596, 580, 551, 579, 599, 596, 570, 572, 565, 605, 589, 606, 597, 596, 592, 546, 565, 556, 580, 549, 565, 605, 597, 605, 607, 567, 550, 596, 591, 559, 609, 543, 542, 578, 542, 556, 612, 571, 586, 604, 548, 578, 594, 571]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "De errors zijn (afgerond tot gehele waarden):\n",
            "[0, 2, 1, 3, 1, 1, 2, 1, 2, 1, 1, 5, 11, 1, 5, 2, 0, 0, 5, 7, 1, 3, 7, 3, 1, 1, 1, 11, 12, 3, 1, 3, 2, 2, 2, 1, 7, 1, 15, 6, 3, 1, 3, 2, 2, 2, 2, 2, 7, 8, 0, 0, 2, 6, 3, 11, 1, 5, 1, 2, 14, 0, 3, 0, 1, 2, 1, 1, 7, 1, 0, 1, 2, 2, 8, 5, 0, 8, 5, 2, 2, 0, 3, 7, 3, 7, 7, 9, 8, 1]\n",
            "De predicties zijn:\n",
            "[543.1195678710938, 581.1173095703125, 553.1925659179688, 561.5105590820312, 590.3085327148438, 590.3825073242188, 585.8142700195312, 588.5744018554688, 583.4104614257812, 544.7052612304688, 570.6768798828125, 569.5421142578125, 594.1670532226562, 602.6397094726562, 572.5318603515625, 589.9437866210938, 595.0695190429688, 609.4680786132812, 560.3439331054688, 603.8513793945312, 587.4366455078125, 544.775634765625, 585.0032348632812, 544.9580688476562, 569.1657104492188, 585.383544921875, 555.9956665039062, 596.5314331054688, 560.8450317382812, 551.948974609375, 568.9502563476562, 601.6889038085938, 572.480712890625, 542.8079223632812, 595.427001953125, 583.3219604492188, 600.3490600585938, 593.8106079101562, 592.7390747070312, 594.6160278320312, 599.711181640625, 598.5044555664062, 603.7901000976562, 552.5440063476562, 607.9065551757812, 559.4692993164062, 587.6868286132812, 581.9603271484375, 588.7330932617188, 556.3636474609375, 553.7904663085938, 581.6688232421875, 560.1608276367188, 593.0269165039062, 557.5735473632812, 597.9032592773438, 565.984619140625, 606.0287475585938, 560.2289428710938, 558.8810424804688, 562.0813598632812, 548.3892822265625, 557.7724609375, 588.6209716796875, 608.1734008789062, 587.7567749023438, 587.4189453125, 579.8685913085938, 601.1587524414062, 611.1654663085938, 591.0308837890625, 609.1363525390625, 580.9850463867188, 559.8198852539062, 601.326416015625, 598.85546875, 579.0516357421875, 570.4320678710938, 570.245849609375, 582.2774047851562, 591.0286254882812, 550.8385620117188, 559.1961059570312, 570.9981079101562, 560.1069946289062, 588.2332153320312, 556.3272094726562, 599.7445678710938, 600.9093627929688, 609.8981323242188]\n",
            "De werkelijke waarden zijn:\n",
            "[543, 583, 554, 559, 589, 589, 588, 590, 585, 544, 570, 565, 605, 602, 568, 592, 595, 609, 555, 611, 586, 542, 592, 542, 568, 586, 555, 608, 549, 549, 568, 605, 570, 545, 593, 582, 607, 593, 578, 589, 603, 600, 607, 551, 610, 557, 586, 584, 582, 548, 554, 582, 558, 599, 555, 609, 565, 611, 559, 557, 548, 548, 555, 589, 609, 590, 586, 581, 608, 612, 591, 610, 583, 562, 609, 604, 579, 562, 565, 580, 593, 551, 556, 564, 557, 595, 549, 609, 609, 611]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "De errors zijn (afgerond tot gehele waarden):\n",
            "[102, 5, 41, 6, 6, 1, 15, 1, 1, 19]\n",
            "De predicties zijn:\n",
            "[682.6215209960938, 552.5196533203125, 633.7633666992188, 590.4338989257812, 589.0726928710938, 603.0750732421875, 591.14599609375, 573.2977294921875, 594.5026245117188, 568.805908203125]\n",
            "De werkelijke waarden zijn:\n",
            "[581, 548, 593, 596, 583, 604, 576, 574, 596, 550]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUVElEQVR4nO3df5QlZX3n8fdHBgSBCITe2YEBh1UOHGQPg6eDKIlrQCI/TMAcVIjBSYI7soGIWTYJ8scu7roGT1R0z7rujkCchB9KwAQC+GMOQlgSgzsI8mvMARFlcGCawAiYXWTgu3/cmrW36aFvd9/bl4d5v86p01VPPVX1rWb43LrPrduVqkKS1J5XjLoASdLcGOCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCUgybIklWRRt/yVJCv66TuHY52b5ML51CuBAa45SHJykluT/CTJxm7+d5NkUp/zupB745Rtz0tyyTT7rCSv6+Zfn+TrSR5PsinJbUmOm9T33CTfT/J0kvVJvjToc6yqY6tq9Xz3k+StSdZP2ffHqur98933DMf9f79PvXwZ4JqVJGcDnwH+BPjnwGLgdOAIYIeuT4D3AY93P2frr4E13f7/GfBB4Mlu3yuAU4G3VdUuwDhww9zPSGqXAa6+JXk18B+B362qK6vqqeq5vareW1XPdF1/CVhCL3hPTrLDLI6xJ7Af8Pmq+mk3/W1V3dJ1+QXga1X1PYCqeqSqVnXbvifJ2in7+/0k13Tzxye5PcmTSR5Kct6L1HFTkvd389sl+USSx5I8ABw/pe9vJ1mX5KkkDyT5QNe+M/AVYK/u3cLTSfaa+i4kyeFJ/q57t/GdJG+dtO63un0+1b3reO+kdb/THfeJJF9L8pqu/eauy3e6Y76n39+/2mKAazbeBLwSuHqGfivoXUVf0S3/6iyO8Y/A/cAlSU5MsnjK+r8H3pfkD5KMJ9lu0rq/Bg5Isv+ktt8ALuvmf0LvHcFu9EL43yQ5sY+a/jXwDuBQelf8J01Zv7Fb/3PAbwMXJHlDVf0EOBb4UVXt0k0/mrxhkr2B64CPAnsA/w64KslY9wLwX4Bjq2pX4M3AHd12JwDnAr8OjAH/E7gcoKre0u3+kO6YAx9i0kuDAa7Z2BN4rKo2b2mYdOX4v5O8JcmrgHcBl1XVs8CVzGIYpXp/nOeXgQeBTwIbkty8JZSr6hLg94C3A38DbEzyR926f6L34nJKV9v+wIHANd36m6rqrqp6vqrupBd4/6qPst4NfLqqHqqqx4E/nlLzdVX1ve7dyN8AX6f3LqQfvwlcX1XXd3WtAdYCW8b8nwcOTrJTVW2oqnu69tOBP66qdd1/j48By7dchWvbYIBrNv4R2HPy3RdV9eaq2q1b9wrgncBm4Pquy6XAsUnGuuXNwPaTd5pky/Kz3T7XV9WZVfVa4DX0rpz/bNIxL62qt9G7kj4d+E9J3t6tvowuwOldff9VF+wkeWOSG5NMJPlxt+2efZz3XsBDk5Z/MKX+Y5P8/ZYPXemFbz/7pTu/d3Uvgpu67X8RWNJdwb+nq3NDkuuSHDhpu89M2uZxIMDefR5XLwMGuGbjm8AzwAkv0mcFsAvwwySPAH9BL7B/o1v/Q2DZlG32oxfsD0/dWVU9BHwWOHiadc9W1V8Ad05avwYYS7KcXpBfNmmTy+hdje9TVa8G/ju90JvJBmCfScv7bplJ8krgKuATwOLuxez6Sfud6c99PgT8eVXtNmnauarO787xa1V1NL3PFL4LfH7Sdh+Yst1OVfV3fZyPXiYMcPWtqjYBHwH+W5KTkuya5BVdWO5M7+rvKHrjwcu76RDg4/xsGOWrwIFJTk2yfZI96L39v6qqNifZPclHkryu2/eewO/QG/ve8qHe8ZOOfSzweuDWrsZn6b1o/Am9MeU1k05hV+Dxqvo/SQ7jZy8qM7kC+GCSpUl2B86ZtG4Hep8LTACbu3p+ZdL6R4Gf7z4Ans4lwK8meXv3YemO3a2HS5MsTnJCNxb+DPA0vSEV6L34fDjJ67vfy6uTvGvKcf9Fn+enVlWVk9OsJuC9wLeAf6IXXLcCK4F/D9w2Tf+96A2PHNwtvxm4BXgC+BFwIbB7t25nYDW9MfCngUfojVXv3a3/deBvu22fBO4CfmvK8X6J3pXvZ6e0n0Rv+OMp4FrgvwKXdOuWddss6pZvAt7fzS8CLqA3TPR94Iwpfc+gF5ibgD8Hvgh8dNJxL+623dT9Ls7bctxu/Rvpjec/3v0+r6N3lb+ka/9xt+1NwEGTtju1O/8n6V2RXzxp3en03jlsAt496n8zTsOZ0v3HliQ1xiEUSWqUAS5JjTLAJalRBrgkNWpOfw5zrvbcc89atmzZnLa96+EfD7aYafzLvbd2p5ckjc5tt932WFWNTW1f0ABftmwZa9eunbnjdNuec92Aq3mhtecfP3MnSVpgSX4wXbtDKJLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRi3oAx00ewvxIIsHfZCF1CSvwCWpUX0HeJLtktye5Npueb8ktya5P8mXkuwwvDIlSVPN5gr8LGDdpOWPAxdU1euAJ4DTBlmYJOnF9RXgSZYCxwMXdssBjgSu7LqsBk4cRoGSpOn1ewX+aeAPgee75Z8HNlXV5m55PbD3dBsmWZlkbZK1ExMT8ypWkvQzMwZ4kncAG6vqtrkcoKpWVdV4VY2PjY3NZReSpGn0cxvhEcCvJTkO2BH4OeAzwG5JFnVX4UuBh4dXpiRpqhmvwKvqw1W1tKqWAScD36iq9wI3Aid13VYAVw+tSknSC8znPvA/Av5tkvvpjYlfNJiSJEn9mNU3MavqJuCmbv4B4LDBlyRJ6offxJSkRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalR/TwTc8ck30rynST3JPlI1/6FJN9Pckc3LR9+uZKkLfp5oMMzwJFV9XSS7YFbknylW/cHVXXl8MqTJG3NjAFeVQU83S1u3001zKIkSTPraww8yXZJ7gA2Amuq6tZu1X9OcmeSC5K8cmhVSpJeoK8Ar6rnqmo5sBQ4LMnBwIeBA4FfAPag95DjF0iyMsnaJGsnJiYGVLYkaVZ3oVTVJuBG4Jiq2lA9zwB/ylYecFxVq6pqvKrGx8bG5l+xJAno7y6UsSS7dfM7AUcD302ypGsLcCJw9zALlST9//q5C2UJsDrJdvQC/4qqujbJN5KMAQHuAE4fYp2SpCn6uQvlTuDQadqPHEpFkqS++E1MSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1Kj+nmk2o5JvpXkO0nuSfKRrn2/JLcmuT/Jl5LsMPxyJUlb9HMF/gxwZFUdAiwHjklyOPBx4IKqeh3wBHDa8MqUJE01Y4B3T55/ulvcvpsKOBK4smtfTe/BxpKkBdLXGHiS7ZLcAWwE1gDfAzZV1eauy3pg761suzLJ2iRrJyYmBlGzJIk+A7yqnquq5cBS4DDgwH4PUFWrqmq8qsbHxsbmWKYkaapZ3YVSVZuAG4E3Absl2fJU+6XAwwOuTZL0Ivq5C2UsyW7d/E7A0cA6ekF+UtdtBXD1sIqUJL3Qopm7sARYnWQ7eoF/RVVdm+Re4ItJPgrcDlw0xDolSVPMGOBVdSdw6DTtD9AbD5ckjYDfxJSkRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalR/TyRZ58kNya5N8k9Sc7q2s9L8nCSO7rpuOGXK0naop8n8mwGzq6qbyfZFbgtyZpu3QVV9YnhlSdJ2pp+nsizAdjQzT+VZB2w97ALkyS9uFmNgSdZRu/xard2TWcmuTPJxUl238o2K5OsTbJ2YmJiXsVKkn6m7wBPsgtwFfChqnoS+BzwWmA5vSv0T063XVWtqqrxqhofGxsbQMmSJOgzwJNsTy+8L62qLwNU1aNV9VxVPQ98Hh9wLEkLqp+7UAJcBKyrqk9Nal8yqds7gbsHX54kaWv6uQvlCOBU4K4kd3Rt5wKnJFkOFPAg8IGhVChJmlY/d6HcAmSaVdcPvhxJUr/8JqYkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmN6ueJPPskuTHJvUnuSXJW175HkjVJ7ut+TvtQY0nScPRzBb4ZOLuqDgIOB85IchBwDnBDVe0P3NAtS5IWyIwBXlUbqurb3fxTwDpgb+AEYHXXbTVw4rCKlCS90KzGwJMsAw4FbgUWV9WGbtUjwOKBViZJelF9B3iSXYCrgA9V1ZOT11VV0Xu48XTbrUyyNsnaiYmJeRUrSfqZvgI8yfb0wvvSqvpy1/xokiXd+iXAxum2rapVVTVeVeNjY2ODqFmSRH93oQS4CFhXVZ+atOoaYEU3vwK4evDlSZK2ZlEffY4ATgXuSnJH13YucD5wRZLTgB8A7x5OiZKk6cwY4FV1C5CtrD5qsOVI0sJbds51Qz/Gg+cfP/B9+k1MSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1Kj+nmk2sVJNia5e1LbeUkeTnJHNx033DIlSVP1cwX+BeCYadovqKrl3XT9YMuSJM1kxgCvqpuBxxegFknSLPTzUOOtOTPJ+4C1wNlV9cR0nZKsBFYC7LvvvvM4nLRtGPbzGYfxbEaNxlw/xPwc8FpgObAB+OTWOlbVqqoar6rxsbGxOR5OkjTVnAK8qh6tqueq6nng88Bhgy1LkjSTOQV4kiWTFt8J3L21vpKk4ZhxDDzJ5cBbgT2TrAf+A/DWJMuBAh4EPjDEGiVJ05gxwKvqlGmaLxpCLZKkWfCbmJLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDVqxgBPcnGSjUnuntS2R5I1Se7rfu4+3DIlSVP1cwX+BeCYKW3nADdU1f7ADd2yJGkBzRjgVXUz8PiU5hOA1d38auDEAdclSZrBXMfAF1fVhm7+EWDx1jomWZlkbZK1ExMTczycJGmqeX+IWVVF7+HGW1u/qqrGq2p8bGxsvoeTJHXmGuCPJlkC0P3cOLiSJEn9mGuAXwOs6OZXAFcPphxJUr/6uY3wcuCbwAFJ1ic5DTgfODrJfcDbumVJ0gJaNFOHqjplK6uOGnAtkqRZ8JuYktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRM/45WW27lp1z3dCP8eD5x7/kji21Yl4BnuRB4CngOWBzVY0PoihJ0swGcQX+y1X12AD2I0maBcfAJalR870CL+DrSQr4H1W1amqHJCuBlQD77rvvPA83Go7HSnopmu8V+C9W1RuAY4EzkrxlaoeqWlVV41U1PjY2Ns/DSZK2mFeAV9XD3c+NwF8Chw2iKEnSzOYc4El2TrLrlnngV4C7B1WYJOnFzWcMfDHwl0m27OeyqvrqQKqSJM1ozgFeVQ8AhwywFknSLHgboSQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElq1CCeSi+9rGzLz0Ad9rm/2HmP8tit8gpckho1rwBPckySf0hyf5JzBlWUJGlm83km5nbAZ+k9kf4g4JQkBw2qMEnSi5vPFfhhwP1V9UBV/RT4InDCYMqSJM0kVTW3DZOTgGOq6v3d8qnAG6vqzCn9VgIru8UDgH+Ye7lN2RN4bNRFjIDnvW3xvBfGa6pqbGrj0O9CqapVwKphH+elJsnaqhofdR0LzfPetnjeozWfIZSHgX0mLS/t2iRJC2A+Af6/gP2T7JdkB+Bk4JrBlCVJmsmch1CqanOSM4GvAdsBF1fVPQOrrH3b3LBRx/PetnjeIzTnDzElSaPlNzElqVEGuCQ1ygAfoCT7JLkxyb1J7kly1qhrWkhJtktye5JrR13LQkmyW5Irk3w3ybokbxp1TQshye93/8bvTnJ5kh1HXdOwJLk4ycYkd09q2yPJmiT3dT93H0VtBvhgbQbOrqqDgMOBM7axPy9wFrBu1EUssM8AX62qA4FD2AbOP8newAeB8ao6mN5NDCePtqqh+gJwzJS2c4Abqmp/4IZuecEZ4ANUVRuq6tvd/FP0/mfee7RVLYwkS4HjgQtHXctCSfJq4C3ARQBV9dOq2jTaqhbMImCnJIuAVwE/GnE9Q1NVNwOPT2k+AVjdza8GTlzQojoG+JAkWQYcCtw62koWzKeBPwSeH3UhC2g/YAL4027o6MIkO4+6qGGrqoeBTwA/BDYAP66qr4+2qgW3uKo2dPOPAItHUYQBPgRJdgGuAj5UVU+Oup5hS/IOYGNV3TbqWhbYIuANwOeq6lDgJ4zorfRC6sZ7T6D3ArYXsHOS3xxtVaNTvXuxR3I/tgE+YEm2pxfel1bVl0ddzwI5Avi1JA/S+6uURya5ZLQlLYj1wPqq2vIu60p6gf5y9zbg+1U1UVXPAl8G3jzimhbao0mWAHQ/N46iCAN8gJKE3njouqr61KjrWShV9eGqWlpVy+h9mPWNqnrZX5FV1SPAQ0kO6JqOAu4dYUkL5YfA4Ule1f2bP4pt4MPbKa4BVnTzK4CrR1GEAT5YRwCn0rsCvaObjht1URqq3wMuTXInsBz42IjrGbruHceVwLeBu+jlyEviq+XDkORy4JvAAUnWJzkNOB84Osl99N6RnD+S2vwqvSS1yStwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIa9X8BYN70GAUiiHkAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}