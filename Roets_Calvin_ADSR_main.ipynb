{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1HQhnNfZ79jT"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import natsort\n",
        "import re \n",
        "import sys\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Eerst delay_dataset uploaden naar google colab en wachten tot upload compleet is\n",
        "standaarddirectory = os.getcwd()                  #standaarddirectory van google colab opslaan zodat we altijd terug kunnen keren naar deze\n",
        "file_name = \"delay_dataset.zip\"                   #de naam van de zipfile met alle data\n",
        "if not os.path.exists(\"stud_train\"):              #Als de data nog niet uitgepakt is en deze folder dus nog niet bestaat, gaan we dit doen\n",
        "  try:\n",
        "    with ZipFile(file_name,'r') as zipper:\n",
        "      zipper.extractall()\n",
        "      print(\"extractie data klaar\")\n",
        "  except:\n",
        "    sys.exit(\"Fout bij extractie data, zeker dat deze goed is geupload?\")\n",
        "\n",
        "if not os.path.exists(\"stud_train_combined_ASDR\"):    #Een folder waarin we de gecombineerde ASDR train signalen van 1024 samples zullen opslaan\n",
        "  os.makedirs(\"stud_train_combined_ASDR\")\n",
        "if not os.path.exists(\"stud_train_combined_GAUSS\"):   #Een folder waarin we de gecombineerde GAUSS train signalen van 1024 samples zullen opslaan\n",
        "  os.makedirs(\"stud_train_combined_GAUSS\")\n",
        "if not os.path.exists(\"stud_train_combined_SBOX\"):    #Een folder waarin we de gecombineerde SBOX train signalen van 1024 samples zullen opslaan\n",
        "  os.makedirs(\"stud_train_combined_SBOX\")\n",
        "\n",
        "if not os.path.exists(\"stud_test_combined_ASDR\"):    #Een folder waarin we de gecombineerde ASDR test signalen van 1024 samples zullen opslaan\n",
        "  os.makedirs(\"stud_test_combined_ASDR\")\n",
        "if not os.path.exists(\"stud_test_combined_GAUSS\"):   #Een folder waarin we de gecombineerde GAUSS test signalen van 1024 samples zullen opslaan\n",
        "  os.makedirs(\"stud_test_combined_GAUSS\")\n",
        "if not os.path.exists(\"stud_test_combined_SBOX\"):    #Een folder waarin we de gecombineerde SBOX test signalen van 1024 samples zullen opslaan\n",
        "  os.makedirs(\"stud_test_combined_SBOX\")"
      ],
      "metadata": {
        "id": "mgGGxSjv8Icw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# variable declaration\n",
        "train_set = 'stud_train'  #een string voor de folder met de trainsamples\n",
        "test_set = 'stud_test'    #een string voor de folder met de testsamples\n",
        "delaypiekASDR = []    #arrays met werkelijke delays tussen de pieken (cijfers voor training en validatie)\n",
        "delaypiekGAUSS = []\n",
        "delaypiekSBOX = []\n",
        "delaypiekASDRtest = []    #arrays met werkelijke delays tussen de pieken (cijfers voor testing)\n",
        "delaypiekGAUSStest = []\n",
        "delaypiekSBOXtest = []\n",
        "grafieknummer = 0 #variabele voor grafieknummering"
      ],
      "metadata": {
        "id": "sokPDAPy8KV4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Geeft een array met strings weer waarin de namen van de files in die map staan\n",
        "def laadarraymetfilenamenuitmap(map):\n",
        "    filenames = os.listdir(map)  # array met alle filenames van in folder\n",
        "    filenames.sort()\n",
        "    return filenames"
      ],
      "metadata": {
        "id": "TgGQgK3V8M1u"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot het signaal van een numpy array aan de hand van een megegeven signaalbestandsnaam\n",
        "#Functie werd enkel gebruikt in het begin voor de twee verschillende signalen van 512 samples te visualiseren op 1 grafiek, niet meer nodig en niet meer gebruikt verder\n",
        "def plotsignaal(signaal, evencheck, nummer, x = np.arange(0,512)): #signaal is naam bestand tussen aanhalingstekens\n",
        "    if evencheck % 2 == 0:                                        #evencheck wordt gebruikt om elke keer twee signalen samen op 1 grafiek te zetten met elk een verschillend kleur\n",
        "        kleur = \"red\"         #paar van signalen respectievelijk rood en blauw weergeven zodat het verschil duidelijk is\n",
        "    else:\n",
        "        kleur = \"blue\"\n",
        "    plot = plt.figure(nummer)\n",
        "    plt.xlabel(\"samples\")\n",
        "    plt.ylabel(\"amplitude\")\n",
        "    plt.plot(x,np.load(signaal), color=kleur)"
      ],
      "metadata": {
        "id": "ddKNHGvW8Ok1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Geeft de waarde van de positie van die piek terug aan de hand van de bestandsnaam\n",
        "def geefpositiepiek(signaal):\n",
        "  truncatedsignaal = (signaal.split(\"P_\",1)[1]) #alles voor de xxx wegdoen dus BV ASDR0_P_ wegdoen\n",
        "  piek = ''.join(x for x in truncatedsignaal[0:3] if x.isdigit()) #drie eerstvolgende karakters overlopen en als deze een cijfer is, maakt deze deel uit van de piek bv: 211_SNR20 wordt 211, 8_SNR26 wordt 8\n",
        "  return piek"
      ],
      "metadata": {
        "id": "W3pSnBvJ8QUP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#voegt de array van twee signalen samen om 1 vector van 1024 samples te bekomen\n",
        "def voegsamen(signaal1, signaal2):\n",
        "  return np.concatenate([np.load(signaal1), np.load(signaal2)])"
      ],
      "metadata": {
        "id": "xzRdHkg08R93"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wordt gebruikt om de lijst met de files te sorten op numerische orde ipv alfabetische orde om sortering van 0 1 10 11 ... 19 2 20 21 ... 29 3 30 31 etc te voorkomen maar 0 1 2 3 4 ... 99\n",
        "#outsourced functies\n",
        "def atoi(text):\n",
        "    return int(text) if text.isdigit() else text\n",
        "\n",
        "def natural_keys(text):\n",
        "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
      ],
      "metadata": {
        "id": "RIRBSs8k8TcZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wordt gebruikt om de 200 signalen van 512 te combineren naar 100 van 1024\n",
        "def combinedata(folder, dir, delayarray, typesignaal = \"\", testoftrain = \"\", aantalgrafiekenplotten = 0):\n",
        "  nummer, evencheck = 1, 0\n",
        "  for data in folder:\n",
        "    evencheck += 1\n",
        "    if evencheck % 2 == 0:     #controleert als we aan een even file zitten, zodat we deze kunnen samenvoegen met de oneven file die ervoor kwam\n",
        "      os.chdir(f\"stud_{testoftrain}\")         #folder binnengaan waar we willen samenvoegen\n",
        "      masterfile = voegsamen(previous, data) #masterfile is een array van 1024 nu\n",
        "      os.chdir(standaarddirectory)\n",
        "      os.chdir(dir)                         #folder binnengaan waar we willen saven\n",
        "      savename = f\"{nummer}{typesignaal}.npy\"\n",
        "      np.save(savename,masterfile)\n",
        "      os.chdir(standaarddirectory)\n",
        "      nummer += 1\n",
        "      delayarray.append(512-int(geefpositiepiek(previous))+int(geefpositiepiek(data)))    #512-piek1+piek2 is waarde van delay\n",
        "\n",
        "      #plotten voor eerste paar grafieken, mooie visualisatie als controle, wordt als default niet gedaan want variabele aantalgrafiekenplotten is 0\n",
        "      if nummer <= aantalgrafiekenplotten:  #max 20 grafieken door memory limiet, dus aantalgrafiekenplotten niet groter dan 20 maken\n",
        "        plot= plt.figure(nummer)\n",
        "        plt.plot(np.arange(0, 1024),masterfile, color=\"red\")\n",
        "\n",
        "    previous = data"
      ],
      "metadata": {
        "id": "COoxeWEx8VB9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotpredictieerrors(predictionslist, delaypiek, titel = '', typesign = 'test'):\n",
        "  global grafieknummer\n",
        "\n",
        "  #x zorgt voor een juiste dimensionering van de x as in de grafiek\n",
        "  if typesign == 'test':\n",
        "    x = 100+1\n",
        "  elif typesign == 'train':\n",
        "    x = 90+1\n",
        "  elif typesign == 'validation':\n",
        "    x = 10+1\n",
        "  elif typesign == 'totaltest':\n",
        "    x = 3*100+1\n",
        "  elif typesign == 'totaltrain':\n",
        "    x = 3*90+1\n",
        "  elif typesign == 'totalvalidation':\n",
        "    x = 3*10+1\n",
        "\n",
        "  error_list = []   #absolute waarde van de fout van predictie \n",
        "  for error1, error2 in zip(predictionslist, delaypiek):\n",
        "    error_list.append(round(abs(error1 - error2)))\n",
        "\n",
        "  y = (sum(error_list)/len(error_list)) #y waarde voor schaling y as grafiek\n",
        "  print(\"De errors zijn (afgerond tot gehele waarden):\")\n",
        "  print(error_list)\n",
        "  print(\"De predicties zijn:\")\n",
        "  print(predictionslist)\n",
        "  print(\"De werkelijke waarden zijn:\")\n",
        "  print(delaypiek)\n",
        "\n",
        "  #visualiseren error\n",
        "  bar = plt.figure(grafieknummer)\n",
        "  grafieknummer += 1\n",
        "  plt.bar(np.arange(1, x), error_list)\n",
        "  plt.ylim(0, y+25)\n",
        "  plt.title(titel)\n",
        "  plt.show()\n",
        "  print() "
      ],
      "metadata": {
        "id": "fTOu4cxI8W0p"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main\n",
        "#filenames inlezen\n",
        "filenames = laadarraymetfilenamenuitmap(train_set)\n",
        "filenamesASDR = filenames[0:200]\n",
        "filenamesGAUSS = filenames[200:400]\n",
        "filenamesSBOX = filenames[400:600]\n",
        "\n",
        "filenamestest = laadarraymetfilenamenuitmap(test_set)\n",
        "filenamesASDRtest = filenamestest[0:200]\n",
        "filenamesGAUSStest = filenamestest[200:400]\n",
        "filenamesSBOXtest = filenamestest[400:600]\n",
        "\n",
        "#sorteren op numerische wijze ipv alfabetische wijze\n",
        "filenamesASDR.sort(key=natural_keys)\n",
        "filenamesGAUSS.sort(key=natural_keys)\n",
        "filenamesSBOX.sort(key=natural_keys)\n",
        "filenamesASDRtest.sort(key=natural_keys)\n",
        "filenamesGAUSStest.sort(key=natural_keys)\n",
        "filenamesSBOXtest.sort(key=natural_keys)"
      ],
      "metadata": {
        "id": "UDMNtMCl8ZeF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(standaarddirectory)\n",
        "#Nu gaan we de 6 folders opvullen waarin de files gecombineerd worden tot 100 signalen van 1024 samples\n",
        "combinedata(filenamesASDR, \"stud_train_combined_ASDR\", delaypiekASDR, \"ASDR\", \"train\")\n",
        "combinedata(filenamesGAUSS, \"stud_train_combined_GAUSS\", delaypiekGAUSS, \"GAUSS\", \"train\")\n",
        "combinedata(filenamesSBOX, \"stud_train_combined_SBOX\", delaypiekSBOX, \"SBOX\", \"train\")\n",
        "\n",
        "combinedata(filenamesASDRtest, \"stud_test_combined_ASDR\", delaypiekASDRtest, \"ASDR\", \"test\")\n",
        "combinedata(filenamesGAUSStest, \"stud_test_combined_GAUSS\", delaypiekGAUSStest, \"GAUSS\", \"test\")\n",
        "combinedata(filenamesSBOXtest, \"stud_test_combined_SBOX\", delaypiekSBOXtest, \"SBOX\", \"test\")"
      ],
      "metadata": {
        "id": "T7z9o7Qt8j2r"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEURAL NETWERK MODEL"
      ],
      "metadata": {
        "id": "xSd4YnRa8nTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TENSOR Object maken voor x waarden NN training\n",
        "os.chdir(standaarddirectory)\n",
        "os.chdir(\"stud_train_combined_ASDR\")\n",
        "\n",
        "#Traindata\n",
        "#We gebruiken deze traindata om het NN te trainen\n",
        "samplesASDR = [np.load(f\"{x}ASDR.npy\") for x in range(1, 91)]\n",
        "samplesASDR = tf.convert_to_tensor(samplesASDR)\n",
        "\n",
        "#Validatiedata\n",
        "#We gebruiken de laatste 10% als validatiedata, deze data gebruiken we om de performantie van het NN te evalueren TIJDENS het trainen en zo de hyperparameters aan te passen. Het nn ziet validatiedata NIET op voorhand, in tegenstelling tot trainingsdata\n",
        "samplesASDRvalidation = [np.load(f\"{x}ASDR.npy\") for x in range(91, 101)]\n",
        "samplesASDRvalidation = tf.convert_to_tensor(samplesASDRvalidation)\n",
        "\n",
        "os.chdir(standaarddirectory)"
      ],
      "metadata": {
        "id": "tWaRs95a8lPl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TENSOR Object maken voor x waarden NN testing\n",
        "os.chdir(standaarddirectory)\n",
        "os.chdir(\"stud_test_combined_ASDR\")\n",
        "\n",
        "#Testdata\n",
        "#We gebruiken deze testdata om het NN te evalueren\n",
        "samplesASDRtest = [np.load(f\"{x}ASDR.npy\") for x in range(1, 101)]\n",
        "samplesASDRtest = tf.convert_to_tensor(samplesASDRtest)\n",
        "\n",
        "os.chdir(standaarddirectory)"
      ],
      "metadata": {
        "id": "5NiIM0WY9Alt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TENSOR object maken voor y waarden NN training (de delaywaarden tussen de pieken)\n",
        "\n",
        "#Traindata\n",
        "delayASDR = pd.DataFrame(data = delaypiekASDR[0:90])\n",
        "delayASDR = tf.convert_to_tensor(delayASDR)\n",
        "\n",
        "#Validatiedata\n",
        "delayASDRvalidation = pd.DataFrame(data = delaypiekASDR[90:])\n",
        "delayASDRvalidation = tf.convert_to_tensor(delayASDRvalidation)"
      ],
      "metadata": {
        "id": "g640ZpP_9DzK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model aanmaken\n",
        "modelASDR = tf.keras.Sequential()\n",
        "modelASDR.add(layers.Dense(1024, activation='relu', input_shape=(1024,)))\n",
        "modelASDR.add(layers.Dense(718, activation='relu'))\n",
        "modelASDR.add(layers.Dense(512, activation='relu'))\n",
        "modelASDR.add(layers.Dense(256, activation='relu'))\n",
        "modelASDR.add(layers.Dense(128, activation='relu'))\n",
        "modelASDR.add(layers.Dense(32, activation='relu'))\n",
        "modelASDR.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "4izhTj7N9FXG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelASDR.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT2TBB-o9Gtf",
        "outputId": "8fb0af34-52a0-4125-c3fd-252abbd753c2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 718)               735950    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 512)               368128    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,322,063\n",
            "Trainable params: 2,322,063\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimizer, loss function en metrics toevoegen aan model en compileren\n",
        "modelASDR.compile(optimizer='Adam', loss='mse', metrics=['mse'])\n",
        "K.set_value(modelASDR.optimizer.learning_rate, 0.0001)"
      ],
      "metadata": {
        "id": "2KKvWo7b9IGY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Trainen\n",
        "history1 = modelASDR.fit(samplesASDR,\n",
        "                        delayASDR,\n",
        "                        epochs=500, #epochs is het aantal iteraties die we over de data doen\n",
        "                        validation_data=(samplesASDRvalidation,delayASDRvalidation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pdm5oX-a9Jmu",
        "outputId": "b9686afb-c3ce-4b91-d287-f735acf03474"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "3/3 [==============================] - 1s 104ms/step - loss: 332737.4375 - mse: 332737.4375 - val_loss: 327982.9688 - val_mse: 327982.9688\n",
            "Epoch 2/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 332282.8125 - mse: 332282.8125 - val_loss: 327461.4375 - val_mse: 327461.4375\n",
            "Epoch 3/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 331673.5938 - mse: 331673.5938 - val_loss: 326690.8438 - val_mse: 326690.8438\n",
            "Epoch 4/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 330803.5312 - mse: 330803.5312 - val_loss: 325602.6562 - val_mse: 325602.6562\n",
            "Epoch 5/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 329568.1250 - mse: 329568.1250 - val_loss: 324063.9062 - val_mse: 324063.9062\n",
            "Epoch 6/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 327791.0312 - mse: 327791.0312 - val_loss: 321833.0312 - val_mse: 321833.0312\n",
            "Epoch 7/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 325229.6562 - mse: 325229.6562 - val_loss: 318617.0625 - val_mse: 318617.0625\n",
            "Epoch 8/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 321540.7188 - mse: 321540.7188 - val_loss: 313978.8125 - val_mse: 313978.8125\n",
            "Epoch 9/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 316184.5000 - mse: 316184.5000 - val_loss: 307343.5938 - val_mse: 307343.5938\n",
            "Epoch 10/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 308556.9375 - mse: 308556.9375 - val_loss: 297862.5312 - val_mse: 297862.5312\n",
            "Epoch 11/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 297737.4688 - mse: 297737.4688 - val_loss: 284491.4375 - val_mse: 284491.4375\n",
            "Epoch 12/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 282262.5000 - mse: 282262.5000 - val_loss: 266014.6875 - val_mse: 266014.6875\n",
            "Epoch 13/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 261266.0156 - mse: 261266.0156 - val_loss: 241214.5938 - val_mse: 241214.5938\n",
            "Epoch 14/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 233669.6719 - mse: 233669.6719 - val_loss: 208660.7500 - val_mse: 208660.7500\n",
            "Epoch 15/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 197396.0000 - mse: 197396.0000 - val_loss: 167733.0469 - val_mse: 167733.0469\n",
            "Epoch 16/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 153165.0938 - mse: 153165.0938 - val_loss: 119324.4141 - val_mse: 119324.4141\n",
            "Epoch 17/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 102490.0469 - mse: 102490.0469 - val_loss: 67751.6172 - val_mse: 67751.6172\n",
            "Epoch 18/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 51689.3672 - mse: 51689.3672 - val_loss: 23389.8164 - val_mse: 23389.8164\n",
            "Epoch 19/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 15592.9199 - mse: 15592.9199 - val_loss: 3218.2036 - val_mse: 3218.2036\n",
            "Epoch 20/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 11863.3184 - mse: 11863.3184 - val_loss: 13329.2090 - val_mse: 13329.2090\n",
            "Epoch 21/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 25791.7891 - mse: 25791.7891 - val_loss: 18565.6680 - val_mse: 18565.6680\n",
            "Epoch 22/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 25341.2617 - mse: 25341.2617 - val_loss: 9273.9668 - val_mse: 9273.9668\n",
            "Epoch 23/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 13142.9609 - mse: 13142.9609 - val_loss: 3471.7832 - val_mse: 3471.7832\n",
            "Epoch 24/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 6567.0425 - mse: 6567.0425 - val_loss: 5117.7080 - val_mse: 5117.7080\n",
            "Epoch 25/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 7830.6943 - mse: 7830.6943 - val_loss: 8775.9004 - val_mse: 8775.9004\n",
            "Epoch 26/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 9981.7354 - mse: 9981.7354 - val_loss: 10062.7471 - val_mse: 10062.7471\n",
            "Epoch 27/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 10157.1699 - mse: 10157.1699 - val_loss: 8500.7715 - val_mse: 8500.7715\n",
            "Epoch 28/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 8481.7969 - mse: 8481.7969 - val_loss: 5966.3799 - val_mse: 5966.3799\n",
            "Epoch 29/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 6943.4834 - mse: 6943.4834 - val_loss: 4133.7437 - val_mse: 4133.7437\n",
            "Epoch 30/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 6207.8926 - mse: 6207.8926 - val_loss: 3627.8562 - val_mse: 3627.8562\n",
            "Epoch 31/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 6382.4688 - mse: 6382.4692 - val_loss: 3632.7820 - val_mse: 3632.7820\n",
            "Epoch 32/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 6514.7139 - mse: 6514.7139 - val_loss: 3604.4954 - val_mse: 3604.4954\n",
            "Epoch 33/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 6252.2432 - mse: 6252.2432 - val_loss: 3654.2766 - val_mse: 3654.2766\n",
            "Epoch 34/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 5836.2520 - mse: 5836.2520 - val_loss: 3859.7642 - val_mse: 3859.7642\n",
            "Epoch 35/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 5695.9839 - mse: 5695.9839 - val_loss: 4177.7407 - val_mse: 4177.7407\n",
            "Epoch 36/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 5753.7759 - mse: 5753.7759 - val_loss: 4465.9600 - val_mse: 4465.9600\n",
            "Epoch 37/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 5693.7974 - mse: 5693.7974 - val_loss: 4339.0493 - val_mse: 4339.0493\n",
            "Epoch 38/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 5581.6841 - mse: 5581.6841 - val_loss: 4186.5049 - val_mse: 4186.5049\n",
            "Epoch 39/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 5495.3994 - mse: 5495.3994 - val_loss: 3954.8625 - val_mse: 3954.8625\n",
            "Epoch 40/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 5388.4380 - mse: 5388.4380 - val_loss: 3817.3562 - val_mse: 3817.3562\n",
            "Epoch 41/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 5330.2705 - mse: 5330.2705 - val_loss: 3783.0437 - val_mse: 3783.0437\n",
            "Epoch 42/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 5269.1011 - mse: 5269.1011 - val_loss: 3773.4790 - val_mse: 3773.4790\n",
            "Epoch 43/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 5211.0825 - mse: 5211.0825 - val_loss: 3769.2058 - val_mse: 3769.2058\n",
            "Epoch 44/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 5130.7319 - mse: 5130.7319 - val_loss: 3800.3062 - val_mse: 3800.3062\n",
            "Epoch 45/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 5071.5571 - mse: 5071.5566 - val_loss: 3865.6606 - val_mse: 3865.6606\n",
            "Epoch 46/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 5003.8745 - mse: 5003.8745 - val_loss: 3898.3743 - val_mse: 3898.3743\n",
            "Epoch 47/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 4947.5801 - mse: 4947.5806 - val_loss: 3892.4773 - val_mse: 3892.4773\n",
            "Epoch 48/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 4867.0503 - mse: 4867.0503 - val_loss: 3767.4519 - val_mse: 3767.4519\n",
            "Epoch 49/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 4816.0376 - mse: 4816.0376 - val_loss: 3671.4290 - val_mse: 3671.4290\n",
            "Epoch 50/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 4745.0752 - mse: 4745.0752 - val_loss: 3640.8931 - val_mse: 3640.8931\n",
            "Epoch 51/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 4672.0396 - mse: 4672.0396 - val_loss: 3673.3047 - val_mse: 3673.3047\n",
            "Epoch 52/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 4632.6265 - mse: 4632.6265 - val_loss: 3782.4585 - val_mse: 3782.4585\n",
            "Epoch 53/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 4536.5835 - mse: 4536.5835 - val_loss: 3765.1245 - val_mse: 3765.1245\n",
            "Epoch 54/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 4474.9512 - mse: 4474.9512 - val_loss: 3698.8813 - val_mse: 3698.8813\n",
            "Epoch 55/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 4404.2632 - mse: 4404.2632 - val_loss: 3645.9941 - val_mse: 3645.9941\n",
            "Epoch 56/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 4338.7710 - mse: 4338.7710 - val_loss: 3569.5657 - val_mse: 3569.5657\n",
            "Epoch 57/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 4285.2109 - mse: 4285.2109 - val_loss: 3552.1516 - val_mse: 3552.1516\n",
            "Epoch 58/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 4218.6772 - mse: 4218.6772 - val_loss: 3575.9556 - val_mse: 3575.9556\n",
            "Epoch 59/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 4158.6758 - mse: 4158.6758 - val_loss: 3534.6797 - val_mse: 3534.6797\n",
            "Epoch 60/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 4085.3806 - mse: 4085.3806 - val_loss: 3582.9741 - val_mse: 3582.9741\n",
            "Epoch 61/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 4013.2090 - mse: 4013.2090 - val_loss: 3646.1179 - val_mse: 3646.1179\n",
            "Epoch 62/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 3954.6382 - mse: 3954.6382 - val_loss: 3633.8679 - val_mse: 3633.8679\n",
            "Epoch 63/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 3878.5083 - mse: 3878.5083 - val_loss: 3582.7078 - val_mse: 3582.7078\n",
            "Epoch 64/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 3823.5916 - mse: 3823.5916 - val_loss: 3499.7612 - val_mse: 3499.7612\n",
            "Epoch 65/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 3758.2087 - mse: 3758.2087 - val_loss: 3452.0859 - val_mse: 3452.0859\n",
            "Epoch 66/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 3680.8430 - mse: 3680.8430 - val_loss: 3477.4661 - val_mse: 3477.4661\n",
            "Epoch 67/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 3615.6562 - mse: 3615.6562 - val_loss: 3502.9839 - val_mse: 3502.9839\n",
            "Epoch 68/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 3557.8042 - mse: 3557.8042 - val_loss: 3505.6165 - val_mse: 3505.6165\n",
            "Epoch 69/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 3506.4851 - mse: 3506.4851 - val_loss: 3533.2766 - val_mse: 3533.2766\n",
            "Epoch 70/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 3446.1992 - mse: 3446.1992 - val_loss: 3421.5327 - val_mse: 3421.5327\n",
            "Epoch 71/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 3369.6848 - mse: 3369.6848 - val_loss: 3444.3997 - val_mse: 3444.3997\n",
            "Epoch 72/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 3306.2146 - mse: 3306.2146 - val_loss: 3389.4868 - val_mse: 3389.4868\n",
            "Epoch 73/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 3240.9858 - mse: 3240.9858 - val_loss: 3406.9551 - val_mse: 3406.9551\n",
            "Epoch 74/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 3175.7197 - mse: 3175.7197 - val_loss: 3413.4487 - val_mse: 3413.4487\n",
            "Epoch 75/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 3116.4570 - mse: 3116.4570 - val_loss: 3406.7349 - val_mse: 3406.7349\n",
            "Epoch 76/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 3066.2659 - mse: 3066.2659 - val_loss: 3349.2122 - val_mse: 3349.2122\n",
            "Epoch 77/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 2995.2065 - mse: 2995.2065 - val_loss: 3379.0344 - val_mse: 3379.0344\n",
            "Epoch 78/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 2932.5122 - mse: 2932.5122 - val_loss: 3347.7649 - val_mse: 3347.7649\n",
            "Epoch 79/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 2895.7461 - mse: 2895.7461 - val_loss: 3370.1196 - val_mse: 3370.1196\n",
            "Epoch 80/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 2812.1035 - mse: 2812.1035 - val_loss: 3304.1628 - val_mse: 3304.1628\n",
            "Epoch 81/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 2754.2229 - mse: 2754.2229 - val_loss: 3236.2107 - val_mse: 3236.2107\n",
            "Epoch 82/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 2706.2004 - mse: 2706.2004 - val_loss: 3160.4468 - val_mse: 3160.4468\n",
            "Epoch 83/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 2650.5889 - mse: 2650.5889 - val_loss: 3180.0190 - val_mse: 3180.0190\n",
            "Epoch 84/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 2585.5591 - mse: 2585.5591 - val_loss: 3256.5894 - val_mse: 3256.5894\n",
            "Epoch 85/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 2531.9390 - mse: 2531.9390 - val_loss: 3232.6465 - val_mse: 3232.6465\n",
            "Epoch 86/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 2493.9241 - mse: 2493.9241 - val_loss: 3216.7795 - val_mse: 3216.7795\n",
            "Epoch 87/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 2428.3823 - mse: 2428.3823 - val_loss: 3259.6189 - val_mse: 3259.6189\n",
            "Epoch 88/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 2380.0144 - mse: 2380.0144 - val_loss: 3235.5149 - val_mse: 3235.5149\n",
            "Epoch 89/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 2315.3774 - mse: 2315.3774 - val_loss: 3121.7722 - val_mse: 3121.7722\n",
            "Epoch 90/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 2264.6763 - mse: 2264.6763 - val_loss: 3067.0354 - val_mse: 3067.0354\n",
            "Epoch 91/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 2220.9089 - mse: 2220.9089 - val_loss: 3052.1602 - val_mse: 3052.1602\n",
            "Epoch 92/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 2172.6379 - mse: 2172.6379 - val_loss: 3044.2053 - val_mse: 3044.2053\n",
            "Epoch 93/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 2123.7437 - mse: 2123.7437 - val_loss: 3150.6375 - val_mse: 3150.6375\n",
            "Epoch 94/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 2063.7209 - mse: 2063.7209 - val_loss: 3144.6531 - val_mse: 3144.6531\n",
            "Epoch 95/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 2027.3372 - mse: 2027.3372 - val_loss: 3115.1294 - val_mse: 3115.1294\n",
            "Epoch 96/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1972.7715 - mse: 1972.7715 - val_loss: 2995.9331 - val_mse: 2995.9331\n",
            "Epoch 97/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 1925.7118 - mse: 1925.7118 - val_loss: 2958.1958 - val_mse: 2958.1958\n",
            "Epoch 98/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 1884.4059 - mse: 1884.4059 - val_loss: 2925.9849 - val_mse: 2925.9849\n",
            "Epoch 99/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1839.2587 - mse: 1839.2587 - val_loss: 2912.3687 - val_mse: 2912.3687\n",
            "Epoch 100/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1802.1208 - mse: 1802.1208 - val_loss: 2995.4294 - val_mse: 2995.4294\n",
            "Epoch 101/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1756.6365 - mse: 1756.6365 - val_loss: 2981.4683 - val_mse: 2981.4683\n",
            "Epoch 102/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 1708.0330 - mse: 1708.0330 - val_loss: 2896.2930 - val_mse: 2896.2930\n",
            "Epoch 103/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1669.7365 - mse: 1669.7365 - val_loss: 2835.7839 - val_mse: 2835.7839\n",
            "Epoch 104/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1626.2544 - mse: 1626.2544 - val_loss: 2806.0425 - val_mse: 2806.0425\n",
            "Epoch 105/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 1583.9132 - mse: 1583.9132 - val_loss: 2840.6597 - val_mse: 2840.6597\n",
            "Epoch 106/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1533.5493 - mse: 1533.5493 - val_loss: 2886.1108 - val_mse: 2886.1108\n",
            "Epoch 107/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1506.4692 - mse: 1506.4692 - val_loss: 2897.0337 - val_mse: 2897.0337\n",
            "Epoch 108/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 1478.2455 - mse: 1478.2455 - val_loss: 2871.1331 - val_mse: 2871.1331\n",
            "Epoch 109/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1420.0170 - mse: 1420.0170 - val_loss: 2757.2915 - val_mse: 2757.2915\n",
            "Epoch 110/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1410.1237 - mse: 1410.1237 - val_loss: 2673.4351 - val_mse: 2673.4351\n",
            "Epoch 111/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 1365.1160 - mse: 1365.1160 - val_loss: 2721.0188 - val_mse: 2721.0188\n",
            "Epoch 112/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 1320.6427 - mse: 1320.6427 - val_loss: 2795.7422 - val_mse: 2795.7422\n",
            "Epoch 113/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1295.6362 - mse: 1295.6362 - val_loss: 2835.4692 - val_mse: 2835.4692\n",
            "Epoch 114/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 1265.2563 - mse: 1265.2563 - val_loss: 2750.1294 - val_mse: 2750.1294\n",
            "Epoch 115/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1220.2439 - mse: 1220.2439 - val_loss: 2648.8997 - val_mse: 2648.8997\n",
            "Epoch 116/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1189.7328 - mse: 1189.7328 - val_loss: 2624.1411 - val_mse: 2624.1411\n",
            "Epoch 117/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1168.4403 - mse: 1168.4403 - val_loss: 2612.6626 - val_mse: 2612.6626\n",
            "Epoch 118/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 1129.4645 - mse: 1129.4645 - val_loss: 2588.5669 - val_mse: 2588.5669\n",
            "Epoch 119/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1101.9946 - mse: 1101.9946 - val_loss: 2616.1609 - val_mse: 2616.1609\n",
            "Epoch 120/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1068.4709 - mse: 1068.4709 - val_loss: 2617.0981 - val_mse: 2617.0981\n",
            "Epoch 121/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1046.6954 - mse: 1046.6954 - val_loss: 2589.6460 - val_mse: 2589.6460\n",
            "Epoch 122/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1021.5814 - mse: 1021.5814 - val_loss: 2559.0151 - val_mse: 2559.0151\n",
            "Epoch 123/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 992.8656 - mse: 992.8656 - val_loss: 2512.4722 - val_mse: 2512.4722\n",
            "Epoch 124/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 964.9330 - mse: 964.9330 - val_loss: 2517.9333 - val_mse: 2517.9333\n",
            "Epoch 125/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 942.2413 - mse: 942.2413 - val_loss: 2523.5249 - val_mse: 2523.5249\n",
            "Epoch 126/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 917.9289 - mse: 917.9289 - val_loss: 2498.5847 - val_mse: 2498.5847\n",
            "Epoch 127/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 889.2523 - mse: 889.2523 - val_loss: 2445.1147 - val_mse: 2445.1147\n",
            "Epoch 128/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 874.3030 - mse: 874.3030 - val_loss: 2447.7527 - val_mse: 2447.7527\n",
            "Epoch 129/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 855.3935 - mse: 855.3935 - val_loss: 2472.5234 - val_mse: 2472.5234\n",
            "Epoch 130/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 829.9030 - mse: 829.9030 - val_loss: 2450.0564 - val_mse: 2450.0564\n",
            "Epoch 131/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 807.3427 - mse: 807.3427 - val_loss: 2434.6555 - val_mse: 2434.6555\n",
            "Epoch 132/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 787.4512 - mse: 787.4512 - val_loss: 2423.4375 - val_mse: 2423.4375\n",
            "Epoch 133/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 771.6094 - mse: 771.6094 - val_loss: 2453.7151 - val_mse: 2453.7151\n",
            "Epoch 134/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 752.5588 - mse: 752.5588 - val_loss: 2429.3398 - val_mse: 2429.3398\n",
            "Epoch 135/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 737.4495 - mse: 737.4495 - val_loss: 2376.3201 - val_mse: 2376.3201\n",
            "Epoch 136/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 720.0050 - mse: 720.0050 - val_loss: 2346.4053 - val_mse: 2346.4053\n",
            "Epoch 137/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 698.7375 - mse: 698.7375 - val_loss: 2348.9866 - val_mse: 2348.9866\n",
            "Epoch 138/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 684.5564 - mse: 684.5564 - val_loss: 2304.5962 - val_mse: 2304.5962\n",
            "Epoch 139/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 673.4202 - mse: 673.4202 - val_loss: 2281.1733 - val_mse: 2281.1733\n",
            "Epoch 140/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 651.7561 - mse: 651.7561 - val_loss: 2312.0459 - val_mse: 2312.0459\n",
            "Epoch 141/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 634.1917 - mse: 634.1917 - val_loss: 2330.3198 - val_mse: 2330.3198\n",
            "Epoch 142/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 624.3412 - mse: 624.3412 - val_loss: 2303.2097 - val_mse: 2303.2097\n",
            "Epoch 143/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 609.3970 - mse: 609.3970 - val_loss: 2292.0942 - val_mse: 2292.0942\n",
            "Epoch 144/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 594.7243 - mse: 594.7243 - val_loss: 2302.6819 - val_mse: 2302.6819\n",
            "Epoch 145/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 579.1320 - mse: 579.1320 - val_loss: 2282.5391 - val_mse: 2282.5391\n",
            "Epoch 146/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 571.2627 - mse: 571.2627 - val_loss: 2223.4365 - val_mse: 2223.4365\n",
            "Epoch 147/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 554.7942 - mse: 554.7942 - val_loss: 2204.7788 - val_mse: 2204.7788\n",
            "Epoch 148/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 543.2283 - mse: 543.2283 - val_loss: 2216.2241 - val_mse: 2216.2241\n",
            "Epoch 149/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 530.9081 - mse: 530.9081 - val_loss: 2211.7334 - val_mse: 2211.7334\n",
            "Epoch 150/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 521.9150 - mse: 521.9150 - val_loss: 2198.4568 - val_mse: 2198.4568\n",
            "Epoch 151/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 508.9164 - mse: 508.9164 - val_loss: 2199.2622 - val_mse: 2199.2622\n",
            "Epoch 152/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 499.4016 - mse: 499.4016 - val_loss: 2168.6177 - val_mse: 2168.6177\n",
            "Epoch 153/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 491.7656 - mse: 491.7656 - val_loss: 2182.1641 - val_mse: 2182.1641\n",
            "Epoch 154/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 480.5759 - mse: 480.5759 - val_loss: 2153.0464 - val_mse: 2153.0464\n",
            "Epoch 155/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 472.1623 - mse: 472.1623 - val_loss: 2162.2217 - val_mse: 2162.2217\n",
            "Epoch 156/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 460.6187 - mse: 460.6187 - val_loss: 2139.7244 - val_mse: 2139.7244\n",
            "Epoch 157/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 447.7347 - mse: 447.7347 - val_loss: 2134.7671 - val_mse: 2134.7671\n",
            "Epoch 158/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 439.4449 - mse: 439.4449 - val_loss: 2118.8350 - val_mse: 2118.8350\n",
            "Epoch 159/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 433.4691 - mse: 433.4691 - val_loss: 2108.4053 - val_mse: 2108.4053\n",
            "Epoch 160/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 423.1427 - mse: 423.1427 - val_loss: 2114.3936 - val_mse: 2114.3936\n",
            "Epoch 161/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 421.2957 - mse: 421.2957 - val_loss: 2113.2407 - val_mse: 2113.2407\n",
            "Epoch 162/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 409.8781 - mse: 409.8781 - val_loss: 2088.6892 - val_mse: 2088.6892\n",
            "Epoch 163/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 400.8124 - mse: 400.8124 - val_loss: 2057.3628 - val_mse: 2057.3628\n",
            "Epoch 164/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 391.5735 - mse: 391.5735 - val_loss: 2064.0288 - val_mse: 2064.0288\n",
            "Epoch 165/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 390.1481 - mse: 390.1481 - val_loss: 2069.2815 - val_mse: 2069.2815\n",
            "Epoch 166/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 381.7858 - mse: 381.7858 - val_loss: 2052.8235 - val_mse: 2052.8235\n",
            "Epoch 167/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 369.5610 - mse: 369.5610 - val_loss: 2020.5271 - val_mse: 2020.5271\n",
            "Epoch 168/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 367.5709 - mse: 367.5709 - val_loss: 2011.1000 - val_mse: 2011.1000\n",
            "Epoch 169/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 361.6393 - mse: 361.6393 - val_loss: 2050.3948 - val_mse: 2050.3948\n",
            "Epoch 170/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 352.0414 - mse: 352.0414 - val_loss: 2044.6412 - val_mse: 2044.6412\n",
            "Epoch 171/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 343.8419 - mse: 343.8419 - val_loss: 2034.6051 - val_mse: 2034.6051\n",
            "Epoch 172/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 338.6389 - mse: 338.6389 - val_loss: 2014.1523 - val_mse: 2014.1523\n",
            "Epoch 173/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 348.8190 - mse: 348.8190 - val_loss: 1998.1569 - val_mse: 1998.1569\n",
            "Epoch 174/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 324.5225 - mse: 324.5225 - val_loss: 2015.7162 - val_mse: 2015.7162\n",
            "Epoch 175/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 325.1253 - mse: 325.1253 - val_loss: 2020.3740 - val_mse: 2020.3740\n",
            "Epoch 176/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 317.3032 - mse: 317.3032 - val_loss: 1995.6449 - val_mse: 1995.6449\n",
            "Epoch 177/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 315.7442 - mse: 315.7442 - val_loss: 1951.5107 - val_mse: 1951.5107\n",
            "Epoch 178/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 308.4552 - mse: 308.4552 - val_loss: 1960.0924 - val_mse: 1960.0924\n",
            "Epoch 179/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 297.2580 - mse: 297.2580 - val_loss: 1993.2601 - val_mse: 1993.2601\n",
            "Epoch 180/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 294.2032 - mse: 294.2032 - val_loss: 1985.0179 - val_mse: 1985.0179\n",
            "Epoch 181/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 290.4684 - mse: 290.4684 - val_loss: 1953.3922 - val_mse: 1953.3922\n",
            "Epoch 182/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 283.5113 - mse: 283.5113 - val_loss: 1952.6627 - val_mse: 1952.6627\n",
            "Epoch 183/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 275.9855 - mse: 275.9855 - val_loss: 1948.4983 - val_mse: 1948.4983\n",
            "Epoch 184/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 272.6560 - mse: 272.6560 - val_loss: 1949.1166 - val_mse: 1949.1166\n",
            "Epoch 185/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 266.4823 - mse: 266.4823 - val_loss: 1929.2324 - val_mse: 1929.2324\n",
            "Epoch 186/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 262.2359 - mse: 262.2359 - val_loss: 1917.4088 - val_mse: 1917.4088\n",
            "Epoch 187/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 258.5471 - mse: 258.5471 - val_loss: 1920.9965 - val_mse: 1920.9965\n",
            "Epoch 188/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 253.8156 - mse: 253.8156 - val_loss: 1911.6516 - val_mse: 1911.6516\n",
            "Epoch 189/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 253.9360 - mse: 253.9360 - val_loss: 1900.6761 - val_mse: 1900.6761\n",
            "Epoch 190/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 245.5390 - mse: 245.5390 - val_loss: 1889.9554 - val_mse: 1889.9554\n",
            "Epoch 191/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 241.5819 - mse: 241.5819 - val_loss: 1889.2262 - val_mse: 1889.2262\n",
            "Epoch 192/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 238.5164 - mse: 238.5164 - val_loss: 1897.3718 - val_mse: 1897.3718\n",
            "Epoch 193/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 231.1299 - mse: 231.1299 - val_loss: 1902.6403 - val_mse: 1902.6403\n",
            "Epoch 194/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 230.2454 - mse: 230.2454 - val_loss: 1902.7506 - val_mse: 1902.7506\n",
            "Epoch 195/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 227.5246 - mse: 227.5246 - val_loss: 1872.6448 - val_mse: 1872.6448\n",
            "Epoch 196/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 225.8624 - mse: 225.8624 - val_loss: 1858.5287 - val_mse: 1858.5287\n",
            "Epoch 197/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 219.6220 - mse: 219.6220 - val_loss: 1874.6547 - val_mse: 1874.6547\n",
            "Epoch 198/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 213.9671 - mse: 213.9671 - val_loss: 1876.7510 - val_mse: 1876.7510\n",
            "Epoch 199/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 214.0585 - mse: 214.0585 - val_loss: 1872.7494 - val_mse: 1872.7494\n",
            "Epoch 200/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 212.0671 - mse: 212.0671 - val_loss: 1869.1713 - val_mse: 1869.1713\n",
            "Epoch 201/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 205.7540 - mse: 205.7540 - val_loss: 1869.7205 - val_mse: 1869.7205\n",
            "Epoch 202/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 202.5113 - mse: 202.5113 - val_loss: 1862.5496 - val_mse: 1862.5496\n",
            "Epoch 203/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 198.0358 - mse: 198.0358 - val_loss: 1847.0045 - val_mse: 1847.0045\n",
            "Epoch 204/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 194.1016 - mse: 194.1016 - val_loss: 1838.3770 - val_mse: 1838.3770\n",
            "Epoch 205/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 191.4125 - mse: 191.4125 - val_loss: 1837.7029 - val_mse: 1837.7029\n",
            "Epoch 206/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 187.4148 - mse: 187.4148 - val_loss: 1831.3972 - val_mse: 1831.3972\n",
            "Epoch 207/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 185.1724 - mse: 185.1724 - val_loss: 1845.9814 - val_mse: 1845.9814\n",
            "Epoch 208/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 182.3652 - mse: 182.3652 - val_loss: 1844.3512 - val_mse: 1844.3512\n",
            "Epoch 209/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 176.9658 - mse: 176.9658 - val_loss: 1828.8572 - val_mse: 1828.8572\n",
            "Epoch 210/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 176.3086 - mse: 176.3086 - val_loss: 1817.7344 - val_mse: 1817.7344\n",
            "Epoch 211/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 174.2986 - mse: 174.2986 - val_loss: 1807.4547 - val_mse: 1807.4547\n",
            "Epoch 212/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 170.1770 - mse: 170.1770 - val_loss: 1826.1602 - val_mse: 1826.1602\n",
            "Epoch 213/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 166.3969 - mse: 166.3969 - val_loss: 1828.0315 - val_mse: 1828.0315\n",
            "Epoch 214/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 163.7367 - mse: 163.7367 - val_loss: 1814.1738 - val_mse: 1814.1738\n",
            "Epoch 215/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 161.3933 - mse: 161.3933 - val_loss: 1811.3213 - val_mse: 1811.3213\n",
            "Epoch 216/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 160.7697 - mse: 160.7697 - val_loss: 1821.9271 - val_mse: 1821.9271\n",
            "Epoch 217/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 155.3657 - mse: 155.3657 - val_loss: 1803.4368 - val_mse: 1803.4368\n",
            "Epoch 218/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 155.6868 - mse: 155.6868 - val_loss: 1799.2008 - val_mse: 1799.2008\n",
            "Epoch 219/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 151.5236 - mse: 151.5236 - val_loss: 1811.0020 - val_mse: 1811.0020\n",
            "Epoch 220/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 149.5708 - mse: 149.5708 - val_loss: 1800.9451 - val_mse: 1800.9451\n",
            "Epoch 221/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 146.4885 - mse: 146.4885 - val_loss: 1780.1543 - val_mse: 1780.1543\n",
            "Epoch 222/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 145.6096 - mse: 145.6096 - val_loss: 1773.4056 - val_mse: 1773.4056\n",
            "Epoch 223/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 142.3039 - mse: 142.3039 - val_loss: 1781.7898 - val_mse: 1781.7898\n",
            "Epoch 224/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 138.2785 - mse: 138.2785 - val_loss: 1788.9600 - val_mse: 1788.9600\n",
            "Epoch 225/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 137.7957 - mse: 137.7957 - val_loss: 1798.9268 - val_mse: 1798.9268\n",
            "Epoch 226/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 135.8343 - mse: 135.8343 - val_loss: 1783.8344 - val_mse: 1783.8344\n",
            "Epoch 227/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 132.4465 - mse: 132.4465 - val_loss: 1769.0092 - val_mse: 1769.0092\n",
            "Epoch 228/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 131.1483 - mse: 131.1483 - val_loss: 1765.7151 - val_mse: 1765.7151\n",
            "Epoch 229/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 131.2896 - mse: 131.2896 - val_loss: 1769.1787 - val_mse: 1769.1787\n",
            "Epoch 230/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 127.8366 - mse: 127.8366 - val_loss: 1757.8441 - val_mse: 1757.8441\n",
            "Epoch 231/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 125.8427 - mse: 125.8427 - val_loss: 1766.6998 - val_mse: 1766.6998\n",
            "Epoch 232/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 122.4590 - mse: 122.4590 - val_loss: 1766.0007 - val_mse: 1766.0007\n",
            "Epoch 233/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 120.6235 - mse: 120.6235 - val_loss: 1768.2836 - val_mse: 1768.2836\n",
            "Epoch 234/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 118.8335 - mse: 118.8335 - val_loss: 1764.2506 - val_mse: 1764.2506\n",
            "Epoch 235/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 116.7383 - mse: 116.7383 - val_loss: 1761.9265 - val_mse: 1761.9265\n",
            "Epoch 236/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 114.9214 - mse: 114.9214 - val_loss: 1759.6873 - val_mse: 1759.6873\n",
            "Epoch 237/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 114.6485 - mse: 114.6484 - val_loss: 1758.8141 - val_mse: 1758.8141\n",
            "Epoch 238/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 110.6151 - mse: 110.6151 - val_loss: 1754.4459 - val_mse: 1754.4459\n",
            "Epoch 239/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 112.1365 - mse: 112.1365 - val_loss: 1737.8818 - val_mse: 1737.8818\n",
            "Epoch 240/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 109.9819 - mse: 109.9819 - val_loss: 1744.9869 - val_mse: 1744.9869\n",
            "Epoch 241/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 106.8553 - mse: 106.8553 - val_loss: 1742.2168 - val_mse: 1742.2168\n",
            "Epoch 242/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 104.9234 - mse: 104.9234 - val_loss: 1729.6371 - val_mse: 1729.6371\n",
            "Epoch 243/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 103.5175 - mse: 103.5175 - val_loss: 1732.5461 - val_mse: 1732.5461\n",
            "Epoch 244/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 100.7337 - mse: 100.7337 - val_loss: 1735.6006 - val_mse: 1735.6006\n",
            "Epoch 245/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 100.7402 - mse: 100.7402 - val_loss: 1730.6042 - val_mse: 1730.6042\n",
            "Epoch 246/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 98.9629 - mse: 98.9629 - val_loss: 1729.9362 - val_mse: 1729.9362\n",
            "Epoch 247/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 96.9330 - mse: 96.9330 - val_loss: 1726.4641 - val_mse: 1726.4641\n",
            "Epoch 248/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 94.8905 - mse: 94.8905 - val_loss: 1715.7828 - val_mse: 1715.7828\n",
            "Epoch 249/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 94.5170 - mse: 94.5170 - val_loss: 1714.6547 - val_mse: 1714.6547\n",
            "Epoch 250/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 91.7442 - mse: 91.7442 - val_loss: 1719.8473 - val_mse: 1719.8473\n",
            "Epoch 251/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 90.6241 - mse: 90.6241 - val_loss: 1721.8594 - val_mse: 1721.8594\n",
            "Epoch 252/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 89.2406 - mse: 89.2406 - val_loss: 1721.3102 - val_mse: 1721.3102\n",
            "Epoch 253/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 90.1655 - mse: 90.1655 - val_loss: 1718.2703 - val_mse: 1718.2703\n",
            "Epoch 254/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 87.2590 - mse: 87.2590 - val_loss: 1711.8018 - val_mse: 1711.8018\n",
            "Epoch 255/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 85.4165 - mse: 85.4165 - val_loss: 1701.7815 - val_mse: 1701.7815\n",
            "Epoch 256/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 83.8447 - mse: 83.8447 - val_loss: 1695.8975 - val_mse: 1695.8975\n",
            "Epoch 257/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 81.9830 - mse: 81.9830 - val_loss: 1693.9824 - val_mse: 1693.9824\n",
            "Epoch 258/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 81.2917 - mse: 81.2917 - val_loss: 1696.7607 - val_mse: 1696.7607\n",
            "Epoch 259/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 79.4550 - mse: 79.4550 - val_loss: 1701.4602 - val_mse: 1701.4602\n",
            "Epoch 260/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 80.8496 - mse: 80.8496 - val_loss: 1694.2532 - val_mse: 1694.2532\n",
            "Epoch 261/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 76.6006 - mse: 76.6006 - val_loss: 1691.1305 - val_mse: 1691.1305\n",
            "Epoch 262/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 77.0971 - mse: 77.0971 - val_loss: 1691.6781 - val_mse: 1691.6781\n",
            "Epoch 263/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 74.6710 - mse: 74.6710 - val_loss: 1698.0641 - val_mse: 1698.0641\n",
            "Epoch 264/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 74.1489 - mse: 74.1489 - val_loss: 1699.2461 - val_mse: 1699.2461\n",
            "Epoch 265/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 72.3071 - mse: 72.3071 - val_loss: 1689.8796 - val_mse: 1689.8796\n",
            "Epoch 266/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 71.2800 - mse: 71.2800 - val_loss: 1694.8684 - val_mse: 1694.8684\n",
            "Epoch 267/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 70.4478 - mse: 70.4478 - val_loss: 1694.1575 - val_mse: 1694.1575\n",
            "Epoch 268/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 68.6937 - mse: 68.6937 - val_loss: 1691.8948 - val_mse: 1691.8948\n",
            "Epoch 269/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 67.8429 - mse: 67.8429 - val_loss: 1687.4307 - val_mse: 1687.4307\n",
            "Epoch 270/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 66.7980 - mse: 66.7980 - val_loss: 1686.3607 - val_mse: 1686.3607\n",
            "Epoch 271/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 65.7147 - mse: 65.7147 - val_loss: 1693.6414 - val_mse: 1693.6414\n",
            "Epoch 272/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 65.1990 - mse: 65.1990 - val_loss: 1694.8711 - val_mse: 1694.8711\n",
            "Epoch 273/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 64.1951 - mse: 64.1951 - val_loss: 1689.0442 - val_mse: 1689.0442\n",
            "Epoch 274/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 62.6726 - mse: 62.6726 - val_loss: 1686.3269 - val_mse: 1686.3269\n",
            "Epoch 275/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 61.8164 - mse: 61.8164 - val_loss: 1680.1119 - val_mse: 1680.1119\n",
            "Epoch 276/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 61.3568 - mse: 61.3568 - val_loss: 1685.8069 - val_mse: 1685.8069\n",
            "Epoch 277/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 64.1390 - mse: 64.1390 - val_loss: 1686.6946 - val_mse: 1686.6946\n",
            "Epoch 278/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 60.4802 - mse: 60.4802 - val_loss: 1696.1140 - val_mse: 1696.1140\n",
            "Epoch 279/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 59.1456 - mse: 59.1456 - val_loss: 1692.3367 - val_mse: 1692.3367\n",
            "Epoch 280/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 59.9232 - mse: 59.9232 - val_loss: 1683.9062 - val_mse: 1683.9062\n",
            "Epoch 281/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 57.5610 - mse: 57.5610 - val_loss: 1685.3561 - val_mse: 1685.3561\n",
            "Epoch 282/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 55.8780 - mse: 55.8780 - val_loss: 1666.5752 - val_mse: 1666.5752\n",
            "Epoch 283/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 54.9608 - mse: 54.9608 - val_loss: 1664.7732 - val_mse: 1664.7732\n",
            "Epoch 284/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 54.8319 - mse: 54.8319 - val_loss: 1670.9629 - val_mse: 1670.9629\n",
            "Epoch 285/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 53.3355 - mse: 53.3355 - val_loss: 1680.9236 - val_mse: 1680.9236\n",
            "Epoch 286/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 52.2146 - mse: 52.2146 - val_loss: 1686.5391 - val_mse: 1686.5391\n",
            "Epoch 287/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 51.6233 - mse: 51.6233 - val_loss: 1686.6252 - val_mse: 1686.6252\n",
            "Epoch 288/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 51.8078 - mse: 51.8078 - val_loss: 1674.9954 - val_mse: 1674.9954\n",
            "Epoch 289/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 50.1099 - mse: 50.1099 - val_loss: 1660.5664 - val_mse: 1660.5664\n",
            "Epoch 290/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 50.4817 - mse: 50.4817 - val_loss: 1670.5531 - val_mse: 1670.5531\n",
            "Epoch 291/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 48.5958 - mse: 48.5958 - val_loss: 1674.5951 - val_mse: 1674.5951\n",
            "Epoch 292/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 48.0165 - mse: 48.0165 - val_loss: 1674.1586 - val_mse: 1674.1586\n",
            "Epoch 293/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 47.5005 - mse: 47.5005 - val_loss: 1679.1211 - val_mse: 1679.1211\n",
            "Epoch 294/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 46.5657 - mse: 46.5657 - val_loss: 1673.2275 - val_mse: 1673.2275\n",
            "Epoch 295/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 45.4042 - mse: 45.4042 - val_loss: 1663.2502 - val_mse: 1663.2502\n",
            "Epoch 296/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 45.2086 - mse: 45.2086 - val_loss: 1663.3763 - val_mse: 1663.3763\n",
            "Epoch 297/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 44.2285 - mse: 44.2285 - val_loss: 1667.6578 - val_mse: 1667.6578\n",
            "Epoch 298/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 44.6260 - mse: 44.6260 - val_loss: 1669.6052 - val_mse: 1669.6052\n",
            "Epoch 299/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 42.9040 - mse: 42.9040 - val_loss: 1674.5586 - val_mse: 1674.5586\n",
            "Epoch 300/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 42.3790 - mse: 42.3790 - val_loss: 1671.8586 - val_mse: 1671.8586\n",
            "Epoch 301/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 41.4253 - mse: 41.4253 - val_loss: 1665.5420 - val_mse: 1665.5420\n",
            "Epoch 302/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 41.6533 - mse: 41.6533 - val_loss: 1663.1022 - val_mse: 1663.1022\n",
            "Epoch 303/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 40.1112 - mse: 40.1112 - val_loss: 1666.3265 - val_mse: 1666.3265\n",
            "Epoch 304/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 40.0860 - mse: 40.0860 - val_loss: 1670.7490 - val_mse: 1670.7490\n",
            "Epoch 305/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 39.0936 - mse: 39.0936 - val_loss: 1673.0227 - val_mse: 1673.0227\n",
            "Epoch 306/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 41.7788 - mse: 41.7788 - val_loss: 1677.8951 - val_mse: 1677.8951\n",
            "Epoch 307/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 38.1341 - mse: 38.1341 - val_loss: 1679.0701 - val_mse: 1679.0701\n",
            "Epoch 308/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 38.9770 - mse: 38.9770 - val_loss: 1670.5172 - val_mse: 1670.5172\n",
            "Epoch 309/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 37.3242 - mse: 37.3242 - val_loss: 1657.2828 - val_mse: 1657.2828\n",
            "Epoch 310/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 36.9225 - mse: 36.9225 - val_loss: 1657.1530 - val_mse: 1657.1530\n",
            "Epoch 311/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 35.8204 - mse: 35.8204 - val_loss: 1664.7803 - val_mse: 1664.7803\n",
            "Epoch 312/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 35.6882 - mse: 35.6882 - val_loss: 1662.7468 - val_mse: 1662.7468\n",
            "Epoch 313/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 34.6760 - mse: 34.6760 - val_loss: 1664.6820 - val_mse: 1664.6820\n",
            "Epoch 314/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 34.0087 - mse: 34.0087 - val_loss: 1663.1621 - val_mse: 1663.1621\n",
            "Epoch 315/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 33.6754 - mse: 33.6754 - val_loss: 1663.3942 - val_mse: 1663.3942\n",
            "Epoch 316/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 33.0127 - mse: 33.0127 - val_loss: 1664.0049 - val_mse: 1664.0049\n",
            "Epoch 317/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 33.0825 - mse: 33.0825 - val_loss: 1665.5592 - val_mse: 1665.5592\n",
            "Epoch 318/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 32.4854 - mse: 32.4854 - val_loss: 1660.5769 - val_mse: 1660.5769\n",
            "Epoch 319/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 32.0401 - mse: 32.0401 - val_loss: 1666.8674 - val_mse: 1666.8674\n",
            "Epoch 320/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 30.9478 - mse: 30.9478 - val_loss: 1663.3805 - val_mse: 1663.3805\n",
            "Epoch 321/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 31.0728 - mse: 31.0728 - val_loss: 1663.4480 - val_mse: 1663.4480\n",
            "Epoch 322/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 29.9755 - mse: 29.9755 - val_loss: 1660.8717 - val_mse: 1660.8717\n",
            "Epoch 323/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 29.7509 - mse: 29.7509 - val_loss: 1658.2654 - val_mse: 1658.2654\n",
            "Epoch 324/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 29.4866 - mse: 29.4866 - val_loss: 1663.2605 - val_mse: 1663.2605\n",
            "Epoch 325/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 28.9112 - mse: 28.9112 - val_loss: 1665.9431 - val_mse: 1665.9431\n",
            "Epoch 326/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 28.3076 - mse: 28.3076 - val_loss: 1663.0774 - val_mse: 1663.0774\n",
            "Epoch 327/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 28.0312 - mse: 28.0312 - val_loss: 1658.0920 - val_mse: 1658.0920\n",
            "Epoch 328/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 27.4982 - mse: 27.4982 - val_loss: 1657.1829 - val_mse: 1657.1829\n",
            "Epoch 329/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 28.1015 - mse: 28.1015 - val_loss: 1663.7522 - val_mse: 1663.7522\n",
            "Epoch 330/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 27.2075 - mse: 27.2075 - val_loss: 1661.6832 - val_mse: 1661.6832\n",
            "Epoch 331/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 26.9858 - mse: 26.9858 - val_loss: 1665.7932 - val_mse: 1665.7932\n",
            "Epoch 332/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 26.4703 - mse: 26.4703 - val_loss: 1669.4014 - val_mse: 1669.4014\n",
            "Epoch 333/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 25.7605 - mse: 25.7605 - val_loss: 1663.4473 - val_mse: 1663.4473\n",
            "Epoch 334/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 25.5852 - mse: 25.5852 - val_loss: 1659.6082 - val_mse: 1659.6082\n",
            "Epoch 335/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 24.7707 - mse: 24.7707 - val_loss: 1660.9479 - val_mse: 1660.9479\n",
            "Epoch 336/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 24.9870 - mse: 24.9870 - val_loss: 1668.1207 - val_mse: 1668.1207\n",
            "Epoch 337/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 24.3334 - mse: 24.3334 - val_loss: 1667.3528 - val_mse: 1667.3528\n",
            "Epoch 338/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 23.7767 - mse: 23.7767 - val_loss: 1664.5781 - val_mse: 1664.5781\n",
            "Epoch 339/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 23.4765 - mse: 23.4765 - val_loss: 1655.5326 - val_mse: 1655.5326\n",
            "Epoch 340/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 22.9279 - mse: 22.9279 - val_loss: 1655.8484 - val_mse: 1655.8484\n",
            "Epoch 341/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 22.6824 - mse: 22.6824 - val_loss: 1659.7471 - val_mse: 1659.7471\n",
            "Epoch 342/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 22.4911 - mse: 22.4911 - val_loss: 1666.8669 - val_mse: 1666.8669\n",
            "Epoch 343/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 22.5605 - mse: 22.5605 - val_loss: 1661.6508 - val_mse: 1661.6508\n",
            "Epoch 344/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 23.0484 - mse: 23.0484 - val_loss: 1655.7766 - val_mse: 1655.7766\n",
            "Epoch 345/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 21.5002 - mse: 21.5002 - val_loss: 1655.2058 - val_mse: 1655.2058\n",
            "Epoch 346/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 21.4281 - mse: 21.4281 - val_loss: 1666.5413 - val_mse: 1666.5413\n",
            "Epoch 347/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 21.0384 - mse: 21.0384 - val_loss: 1671.8014 - val_mse: 1671.8014\n",
            "Epoch 348/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 21.5850 - mse: 21.5850 - val_loss: 1655.4508 - val_mse: 1655.4508\n",
            "Epoch 349/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 19.6853 - mse: 19.6853 - val_loss: 1649.5043 - val_mse: 1649.5043\n",
            "Epoch 350/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 20.7067 - mse: 20.7067 - val_loss: 1658.6947 - val_mse: 1658.6947\n",
            "Epoch 351/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 19.3241 - mse: 19.3241 - val_loss: 1674.9973 - val_mse: 1674.9973\n",
            "Epoch 352/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 19.5775 - mse: 19.5775 - val_loss: 1674.2668 - val_mse: 1674.2668\n",
            "Epoch 353/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 18.8220 - mse: 18.8220 - val_loss: 1660.4753 - val_mse: 1660.4753\n",
            "Epoch 354/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 18.5391 - mse: 18.5391 - val_loss: 1654.6904 - val_mse: 1654.6904\n",
            "Epoch 355/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 18.6355 - mse: 18.6355 - val_loss: 1657.9303 - val_mse: 1657.9303\n",
            "Epoch 356/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 17.8980 - mse: 17.8980 - val_loss: 1664.8713 - val_mse: 1664.8713\n",
            "Epoch 357/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 17.7389 - mse: 17.7389 - val_loss: 1670.8516 - val_mse: 1670.8516\n",
            "Epoch 358/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 17.5201 - mse: 17.5201 - val_loss: 1667.9183 - val_mse: 1667.9183\n",
            "Epoch 359/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 18.3739 - mse: 18.3739 - val_loss: 1657.3860 - val_mse: 1657.3860\n",
            "Epoch 360/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 17.2133 - mse: 17.2133 - val_loss: 1653.8939 - val_mse: 1653.8939\n",
            "Epoch 361/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 17.6599 - mse: 17.6599 - val_loss: 1658.8705 - val_mse: 1658.8705\n",
            "Epoch 362/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 16.2708 - mse: 16.2708 - val_loss: 1669.0740 - val_mse: 1669.0740\n",
            "Epoch 363/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 16.7467 - mse: 16.7467 - val_loss: 1663.3588 - val_mse: 1663.3588\n",
            "Epoch 364/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 16.8381 - mse: 16.8381 - val_loss: 1650.4651 - val_mse: 1650.4651\n",
            "Epoch 365/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 16.3686 - mse: 16.3686 - val_loss: 1656.8766 - val_mse: 1656.8766\n",
            "Epoch 366/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 15.8865 - mse: 15.8865 - val_loss: 1662.3137 - val_mse: 1662.3137\n",
            "Epoch 367/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 15.3182 - mse: 15.3182 - val_loss: 1661.7006 - val_mse: 1661.7006\n",
            "Epoch 368/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 15.3111 - mse: 15.3111 - val_loss: 1664.4573 - val_mse: 1664.4573\n",
            "Epoch 369/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 14.8195 - mse: 14.8195 - val_loss: 1660.6780 - val_mse: 1660.6780\n",
            "Epoch 370/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 14.7579 - mse: 14.7579 - val_loss: 1657.5852 - val_mse: 1657.5852\n",
            "Epoch 371/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 14.7865 - mse: 14.7865 - val_loss: 1656.8967 - val_mse: 1656.8967\n",
            "Epoch 372/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 15.1387 - mse: 15.1387 - val_loss: 1663.5605 - val_mse: 1663.5605\n",
            "Epoch 373/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 14.3734 - mse: 14.3734 - val_loss: 1662.7439 - val_mse: 1662.7439\n",
            "Epoch 374/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 13.6247 - mse: 13.6247 - val_loss: 1660.8785 - val_mse: 1660.8785\n",
            "Epoch 375/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 13.6186 - mse: 13.6186 - val_loss: 1656.4795 - val_mse: 1656.4795\n",
            "Epoch 376/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 14.1039 - mse: 14.1039 - val_loss: 1655.0502 - val_mse: 1655.0502\n",
            "Epoch 377/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 13.7722 - mse: 13.7722 - val_loss: 1658.6360 - val_mse: 1658.6360\n",
            "Epoch 378/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 13.1443 - mse: 13.1443 - val_loss: 1668.0872 - val_mse: 1668.0872\n",
            "Epoch 379/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 13.2512 - mse: 13.2512 - val_loss: 1661.0564 - val_mse: 1661.0564\n",
            "Epoch 380/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 12.6422 - mse: 12.6422 - val_loss: 1656.1008 - val_mse: 1656.1008\n",
            "Epoch 381/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 12.5069 - mse: 12.5069 - val_loss: 1656.4821 - val_mse: 1656.4821\n",
            "Epoch 382/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 12.0757 - mse: 12.0757 - val_loss: 1663.9830 - val_mse: 1663.9830\n",
            "Epoch 383/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 11.9697 - mse: 11.9697 - val_loss: 1665.8304 - val_mse: 1665.8304\n",
            "Epoch 384/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 12.0685 - mse: 12.0685 - val_loss: 1663.1375 - val_mse: 1663.1375\n",
            "Epoch 385/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 11.7871 - mse: 11.7871 - val_loss: 1663.5439 - val_mse: 1663.5439\n",
            "Epoch 386/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 11.5177 - mse: 11.5177 - val_loss: 1661.9597 - val_mse: 1661.9597\n",
            "Epoch 387/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 11.2910 - mse: 11.2910 - val_loss: 1663.8082 - val_mse: 1663.8082\n",
            "Epoch 388/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 11.2144 - mse: 11.2144 - val_loss: 1658.3486 - val_mse: 1658.3486\n",
            "Epoch 389/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 10.8471 - mse: 10.8471 - val_loss: 1659.9307 - val_mse: 1659.9307\n",
            "Epoch 390/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 11.0698 - mse: 11.0698 - val_loss: 1661.3242 - val_mse: 1661.3242\n",
            "Epoch 391/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 10.8553 - mse: 10.8553 - val_loss: 1661.9739 - val_mse: 1661.9739\n",
            "Epoch 392/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 10.6471 - mse: 10.6471 - val_loss: 1657.1283 - val_mse: 1657.1283\n",
            "Epoch 393/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 10.1450 - mse: 10.1450 - val_loss: 1657.2748 - val_mse: 1657.2748\n",
            "Epoch 394/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 10.4524 - mse: 10.4524 - val_loss: 1663.9592 - val_mse: 1663.9592\n",
            "Epoch 395/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 10.5057 - mse: 10.5057 - val_loss: 1661.1145 - val_mse: 1661.1145\n",
            "Epoch 396/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 10.2908 - mse: 10.2908 - val_loss: 1656.2029 - val_mse: 1656.2029\n",
            "Epoch 397/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 9.8069 - mse: 9.8069 - val_loss: 1658.1213 - val_mse: 1658.1213\n",
            "Epoch 398/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 9.5191 - mse: 9.5191 - val_loss: 1662.9695 - val_mse: 1662.9695\n",
            "Epoch 399/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 9.5786 - mse: 9.5786 - val_loss: 1662.6560 - val_mse: 1662.6560\n",
            "Epoch 400/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 9.2448 - mse: 9.2448 - val_loss: 1661.2211 - val_mse: 1661.2211\n",
            "Epoch 401/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 9.1201 - mse: 9.1201 - val_loss: 1663.4115 - val_mse: 1663.4115\n",
            "Epoch 402/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 9.0216 - mse: 9.0216 - val_loss: 1657.0931 - val_mse: 1657.0931\n",
            "Epoch 403/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 8.8620 - mse: 8.8620 - val_loss: 1654.6410 - val_mse: 1654.6410\n",
            "Epoch 404/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 8.7236 - mse: 8.7236 - val_loss: 1657.4934 - val_mse: 1657.4934\n",
            "Epoch 405/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 8.5076 - mse: 8.5076 - val_loss: 1663.8590 - val_mse: 1663.8590\n",
            "Epoch 406/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 8.5636 - mse: 8.5636 - val_loss: 1660.6674 - val_mse: 1660.6674\n",
            "Epoch 407/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 8.8728 - mse: 8.8728 - val_loss: 1662.4629 - val_mse: 1662.4629\n",
            "Epoch 408/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 8.2562 - mse: 8.2562 - val_loss: 1666.3102 - val_mse: 1666.3102\n",
            "Epoch 409/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 8.1750 - mse: 8.1750 - val_loss: 1663.6185 - val_mse: 1663.6185\n",
            "Epoch 410/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 8.0237 - mse: 8.0237 - val_loss: 1658.0022 - val_mse: 1658.0022\n",
            "Epoch 411/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 7.8008 - mse: 7.8008 - val_loss: 1660.4688 - val_mse: 1660.4688\n",
            "Epoch 412/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 8.0063 - mse: 8.0063 - val_loss: 1657.8369 - val_mse: 1657.8369\n",
            "Epoch 413/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 7.5614 - mse: 7.5614 - val_loss: 1660.4763 - val_mse: 1660.4763\n",
            "Epoch 414/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 7.6537 - mse: 7.6537 - val_loss: 1663.3499 - val_mse: 1663.3499\n",
            "Epoch 415/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 7.5530 - mse: 7.5530 - val_loss: 1666.2666 - val_mse: 1666.2666\n",
            "Epoch 416/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 7.2644 - mse: 7.2644 - val_loss: 1659.3660 - val_mse: 1659.3660\n",
            "Epoch 417/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 7.4594 - mse: 7.4594 - val_loss: 1660.3086 - val_mse: 1660.3086\n",
            "Epoch 418/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 7.0681 - mse: 7.0681 - val_loss: 1664.2666 - val_mse: 1664.2666\n",
            "Epoch 419/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 7.2220 - mse: 7.2220 - val_loss: 1662.5336 - val_mse: 1662.5336\n",
            "Epoch 420/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 6.9159 - mse: 6.9159 - val_loss: 1660.1316 - val_mse: 1660.1316\n",
            "Epoch 421/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 6.7213 - mse: 6.7213 - val_loss: 1664.0521 - val_mse: 1664.0521\n",
            "Epoch 422/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 7.0035 - mse: 7.0035 - val_loss: 1658.4258 - val_mse: 1658.4258\n",
            "Epoch 423/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 6.8000 - mse: 6.8000 - val_loss: 1660.5593 - val_mse: 1660.5593\n",
            "Epoch 424/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 6.6251 - mse: 6.6251 - val_loss: 1664.0895 - val_mse: 1664.0895\n",
            "Epoch 425/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 6.3175 - mse: 6.3175 - val_loss: 1665.0303 - val_mse: 1665.0303\n",
            "Epoch 426/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 6.3165 - mse: 6.3165 - val_loss: 1657.6383 - val_mse: 1657.6383\n",
            "Epoch 427/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 6.4249 - mse: 6.4249 - val_loss: 1657.6758 - val_mse: 1657.6758\n",
            "Epoch 428/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 6.0330 - mse: 6.0330 - val_loss: 1666.8770 - val_mse: 1666.8770\n",
            "Epoch 429/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 6.1265 - mse: 6.1265 - val_loss: 1665.6488 - val_mse: 1665.6488\n",
            "Epoch 430/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 5.9661 - mse: 5.9661 - val_loss: 1659.3580 - val_mse: 1659.3580\n",
            "Epoch 431/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 5.7847 - mse: 5.7847 - val_loss: 1661.3561 - val_mse: 1661.3561\n",
            "Epoch 432/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 6.0834 - mse: 6.0834 - val_loss: 1662.2488 - val_mse: 1662.2488\n",
            "Epoch 433/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 5.7109 - mse: 5.7109 - val_loss: 1661.0159 - val_mse: 1661.0159\n",
            "Epoch 434/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 5.7951 - mse: 5.7951 - val_loss: 1666.6536 - val_mse: 1666.6536\n",
            "Epoch 435/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 5.9894 - mse: 5.9894 - val_loss: 1666.1455 - val_mse: 1666.1455\n",
            "Epoch 436/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 5.7713 - mse: 5.7713 - val_loss: 1662.6686 - val_mse: 1662.6686\n",
            "Epoch 437/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 5.5332 - mse: 5.5332 - val_loss: 1668.4727 - val_mse: 1668.4727\n",
            "Epoch 438/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 5.4172 - mse: 5.4172 - val_loss: 1668.2795 - val_mse: 1668.2795\n",
            "Epoch 439/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 5.1365 - mse: 5.1365 - val_loss: 1660.9670 - val_mse: 1660.9670\n",
            "Epoch 440/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 5.2182 - mse: 5.2182 - val_loss: 1660.3594 - val_mse: 1660.3594\n",
            "Epoch 441/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 5.3824 - mse: 5.3824 - val_loss: 1664.7810 - val_mse: 1664.7810\n",
            "Epoch 442/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 4.9587 - mse: 4.9587 - val_loss: 1662.7927 - val_mse: 1662.7927\n",
            "Epoch 443/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 5.0839 - mse: 5.0839 - val_loss: 1662.5902 - val_mse: 1662.5902\n",
            "Epoch 444/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 4.6562 - mse: 4.6562 - val_loss: 1666.4727 - val_mse: 1666.4727\n",
            "Epoch 445/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 4.8608 - mse: 4.8608 - val_loss: 1661.9475 - val_mse: 1661.9475\n",
            "Epoch 446/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 4.5559 - mse: 4.5559 - val_loss: 1662.7875 - val_mse: 1662.7875\n",
            "Epoch 447/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 4.6786 - mse: 4.6786 - val_loss: 1664.9763 - val_mse: 1664.9763\n",
            "Epoch 448/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 4.5061 - mse: 4.5061 - val_loss: 1666.4971 - val_mse: 1666.4971\n",
            "Epoch 449/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 4.4218 - mse: 4.4218 - val_loss: 1665.5344 - val_mse: 1665.5344\n",
            "Epoch 450/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 4.4979 - mse: 4.4979 - val_loss: 1665.4186 - val_mse: 1665.4186\n",
            "Epoch 451/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 4.3083 - mse: 4.3083 - val_loss: 1663.6224 - val_mse: 1663.6224\n",
            "Epoch 452/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 4.3350 - mse: 4.3350 - val_loss: 1658.6409 - val_mse: 1658.6409\n",
            "Epoch 453/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 4.4397 - mse: 4.4397 - val_loss: 1663.8170 - val_mse: 1663.8170\n",
            "Epoch 454/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 4.3048 - mse: 4.3048 - val_loss: 1671.2422 - val_mse: 1671.2422\n",
            "Epoch 455/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 4.2374 - mse: 4.2374 - val_loss: 1666.1296 - val_mse: 1666.1296\n",
            "Epoch 456/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 3.9714 - mse: 3.9714 - val_loss: 1660.2246 - val_mse: 1660.2246\n",
            "Epoch 457/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 4.0257 - mse: 4.0257 - val_loss: 1663.6289 - val_mse: 1663.6289\n",
            "Epoch 458/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 3.7881 - mse: 3.7881 - val_loss: 1667.9094 - val_mse: 1667.9094\n",
            "Epoch 459/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 3.8970 - mse: 3.8970 - val_loss: 1669.0605 - val_mse: 1669.0605\n",
            "Epoch 460/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 3.7285 - mse: 3.7285 - val_loss: 1661.4373 - val_mse: 1661.4373\n",
            "Epoch 461/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 3.7302 - mse: 3.7302 - val_loss: 1663.8870 - val_mse: 1663.8870\n",
            "Epoch 462/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 3.6208 - mse: 3.6208 - val_loss: 1665.2507 - val_mse: 1665.2507\n",
            "Epoch 463/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 3.5751 - mse: 3.5751 - val_loss: 1662.3328 - val_mse: 1662.3328\n",
            "Epoch 464/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 3.4602 - mse: 3.4602 - val_loss: 1660.8519 - val_mse: 1660.8519\n",
            "Epoch 465/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 3.4915 - mse: 3.4915 - val_loss: 1661.8884 - val_mse: 1661.8884\n",
            "Epoch 466/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 3.3716 - mse: 3.3716 - val_loss: 1665.7439 - val_mse: 1665.7439\n",
            "Epoch 467/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 3.3482 - mse: 3.3482 - val_loss: 1664.5691 - val_mse: 1664.5691\n",
            "Epoch 468/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 3.3123 - mse: 3.3123 - val_loss: 1664.7203 - val_mse: 1664.7203\n",
            "Epoch 469/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 3.2686 - mse: 3.2686 - val_loss: 1663.5662 - val_mse: 1663.5662\n",
            "Epoch 470/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 3.2394 - mse: 3.2394 - val_loss: 1662.7327 - val_mse: 1662.7327\n",
            "Epoch 471/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 3.1672 - mse: 3.1672 - val_loss: 1662.1426 - val_mse: 1662.1426\n",
            "Epoch 472/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 3.1077 - mse: 3.1077 - val_loss: 1665.7008 - val_mse: 1665.7008\n",
            "Epoch 473/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 3.0587 - mse: 3.0587 - val_loss: 1668.0303 - val_mse: 1668.0303\n",
            "Epoch 474/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 3.0836 - mse: 3.0836 - val_loss: 1667.2449 - val_mse: 1667.2449\n",
            "Epoch 475/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 3.1210 - mse: 3.1210 - val_loss: 1664.1246 - val_mse: 1664.1246\n",
            "Epoch 476/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 2.9447 - mse: 2.9447 - val_loss: 1663.0023 - val_mse: 1663.0023\n",
            "Epoch 477/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 2.9851 - mse: 2.9851 - val_loss: 1664.2292 - val_mse: 1664.2292\n",
            "Epoch 478/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.8720 - mse: 2.8720 - val_loss: 1668.1976 - val_mse: 1668.1976\n",
            "Epoch 479/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.8281 - mse: 2.8281 - val_loss: 1664.4021 - val_mse: 1664.4021\n",
            "Epoch 480/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 2.7441 - mse: 2.7441 - val_loss: 1663.2522 - val_mse: 1663.2522\n",
            "Epoch 481/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 2.7763 - mse: 2.7763 - val_loss: 1667.3076 - val_mse: 1667.3076\n",
            "Epoch 482/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 2.6630 - mse: 2.6630 - val_loss: 1667.1848 - val_mse: 1667.1848\n",
            "Epoch 483/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 2.6625 - mse: 2.6625 - val_loss: 1664.6042 - val_mse: 1664.6042\n",
            "Epoch 484/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 2.5854 - mse: 2.5854 - val_loss: 1662.3893 - val_mse: 1662.3893\n",
            "Epoch 485/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 2.6752 - mse: 2.6752 - val_loss: 1668.3750 - val_mse: 1668.3750\n",
            "Epoch 486/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 2.7565 - mse: 2.7565 - val_loss: 1666.0088 - val_mse: 1666.0088\n",
            "Epoch 487/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.4352 - mse: 2.4352 - val_loss: 1660.3591 - val_mse: 1660.3591\n",
            "Epoch 488/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.6326 - mse: 2.6326 - val_loss: 1664.3812 - val_mse: 1664.3812\n",
            "Epoch 489/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.4847 - mse: 2.4847 - val_loss: 1670.7314 - val_mse: 1670.7314\n",
            "Epoch 490/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.5113 - mse: 2.5113 - val_loss: 1662.4685 - val_mse: 1662.4685\n",
            "Epoch 491/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 2.5103 - mse: 2.5103 - val_loss: 1659.9294 - val_mse: 1659.9294\n",
            "Epoch 492/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 2.3183 - mse: 2.3183 - val_loss: 1665.5090 - val_mse: 1665.5090\n",
            "Epoch 493/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 2.4861 - mse: 2.4861 - val_loss: 1660.9707 - val_mse: 1660.9707\n",
            "Epoch 494/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 2.2774 - mse: 2.2774 - val_loss: 1660.3633 - val_mse: 1660.3633\n",
            "Epoch 495/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.2939 - mse: 2.2939 - val_loss: 1667.4062 - val_mse: 1667.4062\n",
            "Epoch 496/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.2479 - mse: 2.2479 - val_loss: 1667.0912 - val_mse: 1667.0912\n",
            "Epoch 497/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 2.1535 - mse: 2.1535 - val_loss: 1662.8386 - val_mse: 1662.8386\n",
            "Epoch 498/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.1304 - mse: 2.1304 - val_loss: 1659.9785 - val_mse: 1659.9785\n",
            "Epoch 499/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 2.1098 - mse: 2.1098 - val_loss: 1664.2158 - val_mse: 1664.2158\n",
            "Epoch 500/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 2.1084 - mse: 2.1084 - val_loss: 1667.4727 - val_mse: 1667.4727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictionsASDR = modelASDR.predict(samplesASDRtest)\n",
        "predictionsASDRtrain = modelASDR.predict(samplesASDR) #Ook eens testen op traindata voor controle\n",
        "predictionsASDRval = modelASDR.predict(samplesASDRvalidation) #Ook eens testen op validatiedata voor controle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWfL3bBW9LLY",
        "outputId": "d19d0fce-ee0c-4e9c-8d3f-a6e9deb50cde"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 8ms/step\n",
            "3/3 [==============================] - 0s 9ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotten van de errors op testdata\n",
        "predictionslistASDR = predictionsASDR.tolist()  #converteren naar lijst\n",
        "predictionslistASDRflat = [item for sublist in predictionslistASDR for item in sublist] #lijst plat maken\n",
        "plotpredictieerrors(predictionslistASDRflat, delaypiekASDRtest, \"ASDRtestset\")\n",
        "\n",
        "#plotten van de errors op traindata\n",
        "predictionslistASDRtrain = predictionsASDRtrain.tolist()\n",
        "predictionslistASDRtrainflat = [item for sublist in predictionslistASDRtrain for item in sublist] #lijst plat maken\n",
        "plotpredictieerrors(predictionslistASDRtrainflat, delaypiekASDR[0:90], \"ASDRtrainset\", 'train')\n",
        "\n",
        "#plotten van de errors op validatiedata\n",
        "predictionslistASDRval = predictionsASDRval.tolist()\n",
        "predictionslistASDRvalflat = [item for sublist in predictionslistASDRval for item in sublist] #lijst plat maken\n",
        "\n",
        "plotpredictieerrors(predictionslistASDRvalflat, delaypiekASDR[90:], \"ASDRvalidatieset\", 'validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XB_zzNz59OKs",
        "outputId": "59a90fa3-eedf-47c9-a48a-a728c058a021"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "De errors zijn (afgerond tot gehele waarden):\n",
            "[73, 18, 45, 3, 40, 78, 34, 20, 36, 66, 51, 28, 8, 174, 5, 89, 50, 83, 0, 8, 27, 115, 5, 91, 1, 55, 54, 78, 35, 13, 4, 68, 83, 15, 2, 45, 41, 35, 104, 177, 75, 11, 7, 20, 19, 3, 15, 3, 33, 5, 9, 32, 35, 37, 9, 26, 35, 13, 100, 5, 48, 40, 15, 61, 1, 27, 2, 99, 47, 10, 59, 55, 1, 187, 50, 15, 27, 2, 5, 33, 131, 38, 34, 35, 57, 28, 46, 23, 61, 38, 9, 38, 109, 167, 175, 14, 14, 52, 138, 18]\n",
            "De predicties zijn:\n",
            "[523.7854614257812, 623.8143920898438, 506.9789733886719, 596.4047241210938, 599.2847290039062, 482.4405822753906, 596.9556884765625, 563.490478515625, 596.3663330078125, 475.6364440917969, 559.6543579101562, 595.6355590820312, 579.2605590820312, 400.2115478515625, 562.37109375, 631.2314453125, 556.6461791992188, 464.04852294921875, 586.8824462890625, 568.4602661132812, 562.0421142578125, 483.6480407714844, 613.3304443359375, 507.36077880859375, 546.7259521484375, 491.6529541015625, 558.419921875, 643.0857543945312, 583.6692504882812, 562.4070434570312, 541.9799194335938, 648.1077270507812, 462.00799560546875, 565.0921020507812, 549.6791381835938, 567.0518188476562, 529.92822265625, 588.5013427734375, 684.7237548828125, 434.0509338378906, 526.0430908203125, 568.3616943359375, 548.542724609375, 628.6648559570312, 601.987548828125, 586.690673828125, 613.4910278320312, 555.5162963867188, 588.3828735351562, 593.6137084960938, 568.02099609375, 567.4520263671875, 612.046142578125, 606.6072387695312, 595.1392822265625, 561.39013671875, 528.3484497070312, 561.7582397460938, 497.47344970703125, 538.720458984375, 519.9232788085938, 622.3041381835938, 557.2994995117188, 497.1108093261719, 550.66015625, 610.26904296875, 568.7019653320312, 497.0461730957031, 593.6805419921875, 582.6573486328125, 532.7771606445312, 663.2361450195312, 559.093505859375, 360.9457092285156, 612.3390502929688, 593.0006103515625, 585.7066040039062, 595.26318359375, 566.84716796875, 601.626220703125, 476.86260986328125, 593.5938110351562, 597.624755859375, 516.1078491210938, 525.6514282226562, 596.66357421875, 598.94677734375, 612.3975830078125, 543.274169921875, 606.3040161132812, 549.249755859375, 630.6176147460938, 449.8913269042969, 421.3817138671875, 424.43206787109375, 619.9481201171875, 559.56787109375, 640.1508178710938, 425.8235168457031, 582.3684692382812]\n",
            "De werkelijke waarden zijn:\n",
            "[597, 606, 552, 599, 559, 560, 563, 543, 560, 542, 611, 568, 571, 574, 557, 542, 607, 547, 587, 576, 589, 599, 608, 598, 548, 547, 612, 565, 549, 549, 546, 580, 545, 580, 552, 612, 571, 554, 581, 611, 601, 557, 556, 609, 583, 590, 598, 553, 555, 599, 559, 599, 577, 570, 586, 587, 563, 575, 597, 544, 568, 582, 542, 558, 552, 583, 567, 596, 547, 593, 592, 608, 560, 548, 562, 608, 559, 593, 562, 569, 608, 556, 564, 551, 583, 569, 553, 589, 604, 568, 558, 593, 559, 588, 599, 606, 574, 588, 564, 600]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "De errors zijn (afgerond tot gehele waarden):\n",
            "[0, 0, 0, 0, 2, 1, 1, 4, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 10, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
            "De predicties zijn:\n",
            "[573.1157836914062, 558.1198120117188, 587.7859497070312, 558.9317626953125, 559.9136352539062, 609.9338989257812, 605.5886840820312, 563.200927734375, 557.1990966796875, 577.8007202148438, 604.95751953125, 565.010986328125, 551.1027221679688, 566.2727661132812, 607.0494995117188, 600.4268188476562, 572.0574951171875, 577.2695922851562, 589.9096069335938, 569.4927978515625, 551.1187133789062, 565.8960571289062, 584.2965698242188, 590.2920532226562, 603.935791015625, 546.5716552734375, 606.1624755859375, 543.3312377929688, 557.1121826171875, 546.404052734375, 554.0852661132812, 558.1815795898438, 550.06884765625, 599.279052734375, 577.6146850585938, 599.3720092773438, 559.6065673828125, 555.129638671875, 584.046142578125, 583.1668701171875, 574.2068481445312, 552.9766235351562, 557.3271484375, 600.3480224609375, 605.3070678710938, 551.3873291015625, 567.0291748046875, 582.3464965820312, 582.9514770507812, 567.6246337890625, 601.233154296875, 553.1370849609375, 545.0313720703125, 556.1848754882812, 601.4508666992188, 610.03125, 585.0099487304688, 603.313720703125, 589.4961547851562, 542.6475219726562, 556.2255859375, 546.8582153320312, 609.62109375, 542.91064453125, 598.700927734375, 603.9288940429688, 562.2898559570312, 581.33056640625, 598.546875, 584.0294189453125, 554.1685180664062, 567.6845092773438, 602.8175659179688, 583.7080078125, 547.9215087890625, 570.2894287109375, 571.2574462890625, 580.9674682617188, 596.2634887695312, 603.014892578125, 561.9418334960938, 594.7882690429688, 611.6617431640625, 585.2830200195312, 574.193115234375, 574.2838134765625, 603.1138916015625, 598.6937866210938, 546.1439208984375, 589.1708374023438]\n",
            "De werkelijke waarden zijn:\n",
            "[573, 558, 588, 559, 562, 609, 605, 567, 557, 578, 605, 565, 551, 566, 606, 599, 572, 577, 590, 570, 551, 566, 584, 590, 604, 549, 606, 543, 557, 547, 554, 558, 551, 599, 576, 598, 560, 555, 584, 585, 574, 553, 557, 600, 605, 551, 557, 582, 583, 567, 601, 553, 545, 556, 598, 610, 585, 603, 587, 543, 556, 547, 610, 543, 603, 604, 562, 581, 599, 584, 554, 569, 603, 584, 548, 570, 571, 581, 597, 603, 562, 595, 612, 585, 574, 574, 604, 598, 546, 589]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "De errors zijn (afgerond tot gehele waarden):\n",
            "[38, 56, 30, 31, 30, 36, 16, 77, 20, 39]\n",
            "De predicties zijn:\n",
            "[613.7039794921875, 549.9470825195312, 511.77435302734375, 627.7142944335938, 602.6962280273438, 599.8331909179688, 580.1600952148438, 490.3911437988281, 554.8053588867188, 603.3760986328125]\n",
            "De werkelijke waarden zijn:\n",
            "[576, 606, 542, 597, 573, 564, 564, 567, 575, 564]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}